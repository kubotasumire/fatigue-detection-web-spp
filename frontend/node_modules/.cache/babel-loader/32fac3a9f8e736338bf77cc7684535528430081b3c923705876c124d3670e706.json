{"ast":null,"code":"import { __decorate } from \"../../../tslib.es6.js\";\n/* eslint-disable @typescript-eslint/naming-convention */\nimport { serialize } from \"../../../Misc/decorators.js\";\nimport { SerializationHelper } from \"../../../Misc/decorators.serialization.js\";\nimport { Vector3, Matrix, Quaternion, TmpVectors } from \"../../../Maths/math.vector.js\";\nimport { PostProcess } from \"../../postProcess.js\";\nimport { PostProcessRenderPipeline } from \"../postProcessRenderPipeline.js\";\nimport { PostProcessRenderEffect } from \"../postProcessRenderEffect.js\";\nimport { RegisterClass } from \"../../../Misc/typeStore.js\";\nimport { ScreenSpaceReflections2Configuration } from \"../../../Rendering/screenSpaceReflections2Configuration.js\";\nimport { GeometryBufferRenderer } from \"../../../Rendering/geometryBufferRenderer.js\";\nimport { DepthRenderer } from \"../../../Rendering/depthRenderer.js\";\nimport \"../postProcessRenderPipelineManagerSceneComponent.js\";\nimport \"../../../Shaders/screenSpaceReflection2.fragment.js\";\nimport \"../../../Shaders/screenSpaceReflection2Blur.fragment.js\";\nimport \"../../../Shaders/screenSpaceReflection2BlurCombiner.fragment.js\";\nconst trs = Matrix.Compose(new Vector3(0.5, 0.5, 0.5), Quaternion.Identity(), new Vector3(0.5, 0.5, 0.5));\nconst trsWebGPU = Matrix.Compose(new Vector3(0.5, 0.5, 1), Quaternion.Identity(), new Vector3(0.5, 0.5, 0));\n/**\n * Render pipeline to produce Screen Space Reflections (SSR) effect\n *\n * References:\n *   Screen Space Ray Tracing:\n *     - http://casual-effects.blogspot.com/2014/08/screen-space-ray-tracing.html\n *     - https://sourceforge.net/p/g3d/code/HEAD/tree/G3D10/data-files/shader/screenSpaceRayTrace.glsl\n *     - https://github.com/kode80/kode80SSR\n *   SSR:\n *     - general tips: https://sakibsaikia.github.io/graphics/2016/12/26/Screen-Space-Reflection-in-Killing-Floor-2.html\n *     - computation of blur radius from roughness and distance: https://github.com/godotengine/godot/blob/master/servers/rendering/renderer_rd/shaders/effects/screen_space_reflection.glsl\n *     - blur and usage of back depth buffer: https://github.com/kode80/kode80SSR\n */\nexport class SSRRenderingPipeline extends PostProcessRenderPipeline {\n  /**\n   * MSAA sample count, setting this to 4 will provide 4x anti aliasing. (default: 1)\n   */\n  set samples(sampleCount) {\n    if (this._samples === sampleCount) {\n      return;\n    }\n    this._samples = sampleCount;\n    this._buildPipeline();\n  }\n  get samples() {\n    return this._samples;\n  }\n  /**\n   * Gets or sets the minimum value for one of the reflectivity component of the material to consider it for SSR (default: 0.04).\n   * If all r/g/b components of the reflectivity is below or equal this value, the pixel will not be considered reflective and SSR won't be applied.\n   */\n  get reflectivityThreshold() {\n    return this._reflectivityThreshold;\n  }\n  set reflectivityThreshold(threshold) {\n    if (threshold === this._reflectivityThreshold) {\n      return;\n    }\n    if (threshold === 0 && this._reflectivityThreshold !== 0 || threshold !== 0 && this._reflectivityThreshold === 0) {\n      this._reflectivityThreshold = threshold;\n      this._buildPipeline();\n    } else {\n      this._reflectivityThreshold = threshold;\n    }\n  }\n  /**\n   * Gets or sets the downsample factor used to reduce the size of the texture used to compute the SSR contribution (default: 0).\n   * Use 0 to render the SSR contribution at full resolution, 1 to render at half resolution, 2 to render at 1/3 resolution, etc.\n   * Note that it is used only when blurring is enabled (blurDispersionStrength \\> 0), because in that mode the SSR contribution is generated in a separate texture.\n   */\n  get ssrDownsample() {\n    return this._ssrDownsample;\n  }\n  set ssrDownsample(downsample) {\n    if (downsample === this._ssrDownsample) {\n      return;\n    }\n    this._ssrDownsample = downsample;\n    this._buildPipeline();\n  }\n  /**\n   * Gets or sets the blur dispersion strength. Set this value to 0 to disable blurring (default: 0.05)\n   * The reflections are blurred based on the roughness of the surface and the distance between the pixel shaded and the reflected pixel: the higher the distance the more blurry the reflection is.\n   * blurDispersionStrength allows to increase or decrease this effect.\n   */\n  get blurDispersionStrength() {\n    return this._blurDispersionStrength;\n  }\n  set blurDispersionStrength(strength) {\n    if (strength === this._blurDispersionStrength) {\n      return;\n    }\n    const rebuild = strength === 0 && this._blurDispersionStrength !== 0 || strength !== 0 && this._blurDispersionStrength === 0;\n    this._blurDispersionStrength = strength;\n    if (rebuild) {\n      this._buildPipeline();\n    }\n  }\n  _useBlur() {\n    return this._blurDispersionStrength > 0;\n  }\n  /**\n   * Gets or sets the downsample factor used to reduce the size of the textures used to blur the reflection effect (default: 0).\n   * Use 0 to blur at full resolution, 1 to render at half resolution, 2 to render at 1/3 resolution, etc.\n   */\n  get blurDownsample() {\n    return this._blurDownsample;\n  }\n  set blurDownsample(downsample) {\n    if (downsample === this._blurDownsample) {\n      return;\n    }\n    this._blurDownsample = downsample;\n    this._buildPipeline();\n  }\n  /**\n   * Gets or sets whether or not smoothing reflections is enabled (default: false)\n   * Enabling smoothing will require more GPU power.\n   * Note that this setting has no effect if step = 1: it's only used if step \\> 1.\n   */\n  get enableSmoothReflections() {\n    return this._enableSmoothReflections;\n  }\n  set enableSmoothReflections(enabled) {\n    if (enabled === this._enableSmoothReflections) {\n      return;\n    }\n    this._enableSmoothReflections = enabled;\n    this._updateEffectDefines();\n  }\n  /**\n   * Gets or sets the environment cube texture used to define the reflection when the reflected rays of SSR leave the view space or when the maxDistance/maxSteps is reached.\n   */\n  get environmentTexture() {\n    return this._environmentTexture;\n  }\n  set environmentTexture(texture) {\n    this._environmentTexture = texture;\n    this._updateEffectDefines();\n  }\n  /**\n   * Gets or sets the boolean defining if the environment texture is a standard cubemap (false) or a probe (true). Default value is false.\n   * Note: a probe cube texture is treated differently than an ordinary cube texture because the Y axis is reversed.\n   */\n  get environmentTextureIsProbe() {\n    return this._environmentTextureIsProbe;\n  }\n  set environmentTextureIsProbe(isProbe) {\n    this._environmentTextureIsProbe = isProbe;\n    this._updateEffectDefines();\n  }\n  /**\n   * Gets or sets a boolean indicating if the reflections should be attenuated at the screen borders (default: true).\n   */\n  get attenuateScreenBorders() {\n    return this._attenuateScreenBorders;\n  }\n  set attenuateScreenBorders(attenuate) {\n    if (this._attenuateScreenBorders === attenuate) {\n      return;\n    }\n    this._attenuateScreenBorders = attenuate;\n    this._updateEffectDefines();\n  }\n  /**\n   * Gets or sets a boolean indicating if the reflections should be attenuated according to the distance of the intersection (default: true).\n   */\n  get attenuateIntersectionDistance() {\n    return this._attenuateIntersectionDistance;\n  }\n  set attenuateIntersectionDistance(attenuate) {\n    if (this._attenuateIntersectionDistance === attenuate) {\n      return;\n    }\n    this._attenuateIntersectionDistance = attenuate;\n    this._updateEffectDefines();\n  }\n  /**\n   * Gets or sets a boolean indicating if the reflections should be attenuated according to the number of iterations performed to find the intersection (default: true).\n   */\n  get attenuateIntersectionIterations() {\n    return this._attenuateIntersectionIterations;\n  }\n  set attenuateIntersectionIterations(attenuate) {\n    if (this._attenuateIntersectionIterations === attenuate) {\n      return;\n    }\n    this._attenuateIntersectionIterations = attenuate;\n    this._updateEffectDefines();\n  }\n  /**\n   * Gets or sets a boolean indicating if the reflections should be attenuated when the reflection ray is facing the camera (the view direction) (default: false).\n   */\n  get attenuateFacingCamera() {\n    return this._attenuateFacingCamera;\n  }\n  set attenuateFacingCamera(attenuate) {\n    if (this._attenuateFacingCamera === attenuate) {\n      return;\n    }\n    this._attenuateFacingCamera = attenuate;\n    this._updateEffectDefines();\n  }\n  /**\n   * Gets or sets a boolean indicating if the backface reflections should be attenuated (default: false).\n   */\n  get attenuateBackfaceReflection() {\n    return this._attenuateBackfaceReflection;\n  }\n  set attenuateBackfaceReflection(attenuate) {\n    if (this._attenuateBackfaceReflection === attenuate) {\n      return;\n    }\n    this._attenuateBackfaceReflection = attenuate;\n    this._updateEffectDefines();\n  }\n  /**\n   * Gets or sets a boolean indicating if the ray should be clipped to the frustum (default: true).\n   * You can try to set this parameter to false to save some performances: it may produce some artefacts in some cases, but generally they won't really be visible\n   */\n  get clipToFrustum() {\n    return this._clipToFrustum;\n  }\n  set clipToFrustum(clip) {\n    if (this._clipToFrustum === clip) {\n      return;\n    }\n    this._clipToFrustum = clip;\n    this._updateEffectDefines();\n  }\n  /**\n   * Gets or sets a boolean indicating whether the blending between the current color pixel and the reflection color should be done with a Fresnel coefficient (default: false).\n   * It is more physically accurate to use the Fresnel coefficient (otherwise it uses the reflectivity of the material for blending), but it is also more expensive when you use blur (when blurDispersionStrength \\> 0).\n   */\n  get useFresnel() {\n    return this._useFresnel;\n  }\n  set useFresnel(fresnel) {\n    if (this._useFresnel === fresnel) {\n      return;\n    }\n    this._useFresnel = fresnel;\n    this._buildPipeline();\n  }\n  /**\n   * Gets or sets a boolean defining if geometry thickness should be computed automatically (default: false).\n   * When enabled, a depth renderer is created which will render the back faces of the scene to a depth texture (meaning additional work for the GPU).\n   * In that mode, the \"thickness\" property is still used as an offset to compute the ray intersection, but you can typically use a much lower\n   * value than when enableAutomaticThicknessComputation is false (it's even possible to use a value of 0 when using low values for \"step\")\n   * Note that for performance reasons, this option will only apply to the first camera to which the rendering pipeline is attached!\n   */\n  get enableAutomaticThicknessComputation() {\n    return this._enableAutomaticThicknessComputation;\n  }\n  set enableAutomaticThicknessComputation(automatic) {\n    if (this._enableAutomaticThicknessComputation === automatic) {\n      return;\n    }\n    this._enableAutomaticThicknessComputation = automatic;\n    this._buildPipeline();\n  }\n  /**\n   * Gets the depth renderer used to render the back faces of the scene to a depth texture.\n   */\n  get backfaceDepthRenderer() {\n    return this._depthRenderer;\n  }\n  /**\n   * Gets or sets the downsample factor (default: 0) used to create the backface depth texture - used only if enableAutomaticThicknessComputation = true.\n   * Use 0 to render the depth at full resolution, 1 to render at half resolution, 2 to render at 1/4 resolution, etc.\n   * Note that you will get rendering artefacts when using a value different from 0: it's a tradeoff between image quality and performances.\n   */\n  get backfaceDepthTextureDownsample() {\n    return this._backfaceDepthTextureDownsample;\n  }\n  set backfaceDepthTextureDownsample(factor) {\n    if (this._backfaceDepthTextureDownsample === factor) {\n      return;\n    }\n    this._backfaceDepthTextureDownsample = factor;\n    this._resizeDepthRenderer();\n  }\n  /**\n   * Gets or sets a boolean (default: true) indicating if the depth of transparent meshes should be written to the backface depth texture (when automatic thickness computation is enabled).\n   */\n  get backfaceForceDepthWriteTransparentMeshes() {\n    return this._backfaceForceDepthWriteTransparentMeshes;\n  }\n  set backfaceForceDepthWriteTransparentMeshes(force) {\n    if (this._backfaceForceDepthWriteTransparentMeshes === force) {\n      return;\n    }\n    this._backfaceForceDepthWriteTransparentMeshes = force;\n    if (this._depthRenderer) {\n      this._depthRenderer.forceDepthWriteTransparentMeshes = force;\n    }\n  }\n  /**\n   * Gets or sets a boolean indicating if the effect is enabled (default: true).\n   */\n  get isEnabled() {\n    return this._isEnabled;\n  }\n  set isEnabled(value) {\n    if (this._isEnabled === value) {\n      return;\n    }\n    this._isEnabled = value;\n    if (!value) {\n      if (this._cameras !== null) {\n        this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);\n        this._cameras = this._camerasToBeAttached.slice();\n      }\n    } else if (value) {\n      if (!this._isDirty) {\n        if (this._cameras !== null) {\n          this._scene.postProcessRenderPipelineManager.attachCamerasToRenderPipeline(this._name, this._cameras);\n        }\n      } else {\n        this._buildPipeline();\n      }\n    }\n  }\n  /**\n   * Gets or sets a boolean defining if the input color texture is in gamma space (default: true)\n   * The SSR effect works in linear space, so if the input texture is in gamma space, we must convert the texture to linear space before applying the effect\n   */\n  get inputTextureColorIsInGammaSpace() {\n    return this._inputTextureColorIsInGammaSpace;\n  }\n  set inputTextureColorIsInGammaSpace(gammaSpace) {\n    if (this._inputTextureColorIsInGammaSpace === gammaSpace) {\n      return;\n    }\n    this._inputTextureColorIsInGammaSpace = gammaSpace;\n    this._buildPipeline();\n  }\n  /**\n   * Gets or sets a boolean defining if the output color texture generated by the SSR pipeline should be in gamma space (default: true)\n   * If you have a post-process that comes after the SSR and that post-process needs the input to be in a linear space, you must disable generateOutputInGammaSpace\n   */\n  get generateOutputInGammaSpace() {\n    return this._generateOutputInGammaSpace;\n  }\n  set generateOutputInGammaSpace(gammaSpace) {\n    if (this._generateOutputInGammaSpace === gammaSpace) {\n      return;\n    }\n    this._generateOutputInGammaSpace = gammaSpace;\n    this._buildPipeline();\n  }\n  /**\n   * Gets or sets a boolean indicating if the effect should be rendered in debug mode (default: false).\n   * In this mode, colors have this meaning:\n   *   - blue: the ray hit the max distance (we reached maxDistance)\n   *   - red: the ray ran out of steps (we reached maxSteps)\n   *   - yellow: the ray went off screen\n   *   - green: the ray hit a surface. The brightness of the green color is proportional to the distance between the ray origin and the intersection point: A brighter green means more computation than a darker green.\n   * In the first 3 cases, the final color is calculated by mixing the skybox color with the pixel color (if environmentTexture is defined), otherwise the pixel color is not modified\n   * You should try to get as few blue/red/yellow pixels as possible, as this means that the ray has gone further than if it had hit a surface.\n   */\n  get debug() {\n    return this._debug;\n  }\n  set debug(value) {\n    if (this._debug === value) {\n      return;\n    }\n    this._debug = value;\n    this._buildPipeline();\n  }\n  /**\n   * Gets the scene the effect belongs to.\n   * @returns the scene the effect belongs to.\n   */\n  getScene() {\n    return this._scene;\n  }\n  get _geometryBufferRenderer() {\n    if (!this._forceGeometryBuffer) {\n      return null;\n    }\n    return this._scene.geometryBufferRenderer;\n  }\n  get _prePassRenderer() {\n    if (this._forceGeometryBuffer) {\n      return null;\n    }\n    return this._scene.prePassRenderer;\n  }\n  /**\n   * Gets active scene\n   */\n  get scene() {\n    return this._scene;\n  }\n  /**\n   * Returns true if SSR is supported by the running hardware\n   */\n  get isSupported() {\n    const caps = this._scene.getEngine().getCaps();\n    return caps.drawBuffersExtension && caps.texelFetch;\n  }\n  /**\n   * Constructor of the SSR rendering pipeline\n   * @param name The rendering pipeline name\n   * @param scene The scene linked to this pipeline\n   * @param cameras The array of cameras that the rendering pipeline will be attached to (default: scene.cameras)\n   * @param forceGeometryBuffer Set to true if you want to use the legacy geometry buffer renderer (default: false)\n   * @param textureType The texture type used by the different post processes created by SSR (default: 0)\n   */\n  constructor(name, scene, cameras, forceGeometryBuffer = false, textureType = 0) {\n    super(scene.getEngine(), name);\n    /**\n     * The SSR PostProcess effect id in the pipeline\n     */\n    this.SSRRenderEffect = \"SSRRenderEffect\";\n    /**\n     * The blur PostProcess effect id in the pipeline\n     */\n    this.SSRBlurRenderEffect = \"SSRBlurRenderEffect\";\n    /**\n     * The PostProcess effect id in the pipeline that combines the SSR-Blur output with the original scene color\n     */\n    this.SSRCombineRenderEffect = \"SSRCombineRenderEffect\";\n    this._samples = 1;\n    /**\n     * Gets or sets the maxDistance used to define how far we look for reflection during the ray-marching on the reflected ray (default: 1000).\n     * Note that this value is a view (camera) space distance (not pixels!).\n     */\n    this.maxDistance = 1000.0;\n    /**\n     * Gets or sets the step size used to iterate until the effect finds the color of the reflection's pixel. Should be an integer \\>= 1 as it is the number of pixels we advance at each step (default: 1).\n     * Use higher values to improve performances (but at the expense of quality).\n     */\n    this.step = 1.0;\n    /**\n     * Gets or sets the thickness value used as tolerance when computing the intersection between the reflected ray and the scene (default: 0.5).\n     * If setting \"enableAutomaticThicknessComputation\" to true, you can use lower values for \"thickness\" (even 0), as the geometry thickness\n     * is automatically computed thank to the regular depth buffer + the backface depth buffer\n     */\n    this.thickness = 0.5;\n    /**\n     * Gets or sets the current reflection strength. 1.0 is an ideal value but can be increased/decreased for particular results (default: 1).\n     */\n    this.strength = 1;\n    /**\n     * Gets or sets the falloff exponent used to compute the reflection strength. Higher values lead to fainter reflections (default: 1).\n     */\n    this.reflectionSpecularFalloffExponent = 1;\n    /**\n     * Maximum number of steps during the ray marching process after which we consider an intersection could not be found (default: 1000).\n     * Should be an integer value.\n     */\n    this.maxSteps = 1000.0;\n    /**\n     * Gets or sets the factor applied when computing roughness. Default value is 0.2.\n     * When blurring based on roughness is enabled (meaning blurDispersionStrength \\> 0), roughnessFactor is used as a global roughness factor applied on all objects.\n     * If you want to disable this global roughness set it to 0.\n     */\n    this.roughnessFactor = 0.2;\n    /**\n     * Number of steps to skip at start when marching the ray to avoid self collisions (default: 1)\n     * 1 should normally be a good value, depending on the scene you may need to use a higher value (2 or 3)\n     */\n    this.selfCollisionNumSkip = 1;\n    this._reflectivityThreshold = 0.04;\n    this._ssrDownsample = 0;\n    this._blurDispersionStrength = 0.03;\n    this._blurDownsample = 0;\n    this._enableSmoothReflections = false;\n    this._environmentTextureIsProbe = false;\n    this._attenuateScreenBorders = true;\n    this._attenuateIntersectionDistance = true;\n    this._attenuateIntersectionIterations = true;\n    this._attenuateFacingCamera = false;\n    this._attenuateBackfaceReflection = false;\n    this._clipToFrustum = true;\n    this._useFresnel = false;\n    this._enableAutomaticThicknessComputation = false;\n    this._backfaceDepthTextureDownsample = 0;\n    this._backfaceForceDepthWriteTransparentMeshes = true;\n    this._isEnabled = true;\n    this._inputTextureColorIsInGammaSpace = true;\n    this._generateOutputInGammaSpace = true;\n    this._debug = false;\n    this._forceGeometryBuffer = false;\n    this._isDirty = false;\n    this._camerasToBeAttached = [];\n    this._cameras = cameras || scene.cameras;\n    this._cameras = this._cameras.slice();\n    this._camerasToBeAttached = this._cameras.slice();\n    this._scene = scene;\n    this._textureType = textureType;\n    this._forceGeometryBuffer = forceGeometryBuffer;\n    if (this.isSupported) {\n      scene.postProcessRenderPipelineManager.addPipeline(this);\n      if (this._forceGeometryBuffer) {\n        const geometryBufferRenderer = scene.enableGeometryBufferRenderer();\n        if (geometryBufferRenderer) {\n          geometryBufferRenderer.enableReflectivity = true;\n          geometryBufferRenderer.useSpecificClearForDepthTexture = true;\n        }\n      } else {\n        const prePassRenderer = scene.enablePrePassRenderer();\n        if (prePassRenderer) {\n          prePassRenderer.useSpecificClearForDepthTexture = true;\n          prePassRenderer.markAsDirty();\n        }\n      }\n      this._buildPipeline();\n    }\n  }\n  /**\n   * Get the class name\n   * @returns \"SSRRenderingPipeline\"\n   */\n  getClassName() {\n    return \"SSRRenderingPipeline\";\n  }\n  /**\n   * Adds a camera to the pipeline\n   * @param camera the camera to be added\n   */\n  addCamera(camera) {\n    this._camerasToBeAttached.push(camera);\n    this._buildPipeline();\n  }\n  /**\n   * Removes a camera from the pipeline\n   * @param camera the camera to remove\n   */\n  removeCamera(camera) {\n    const index = this._camerasToBeAttached.indexOf(camera);\n    this._camerasToBeAttached.splice(index, 1);\n    this._buildPipeline();\n  }\n  /**\n   * Removes the internal pipeline assets and detaches the pipeline from the scene cameras\n   * @param disableGeometryBufferRenderer if the geometry buffer renderer should be disabled\n   */\n  dispose(disableGeometryBufferRenderer = false) {\n    this._disposeDepthRenderer();\n    this._disposePostProcesses();\n    if (disableGeometryBufferRenderer) {\n      this._scene.disableGeometryBufferRenderer();\n    }\n    this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);\n    super.dispose();\n  }\n  _getTextureSize() {\n    const engine = this._scene.getEngine();\n    const prePassRenderer = this._prePassRenderer;\n    let textureSize = {\n      width: engine.getRenderWidth(),\n      height: engine.getRenderHeight()\n    };\n    if (prePassRenderer && this._scene.activeCamera?._getFirstPostProcess() === this._ssrPostProcess) {\n      const renderTarget = prePassRenderer.getRenderTarget();\n      if (renderTarget && renderTarget.textures) {\n        textureSize = renderTarget.textures[prePassRenderer.getIndex(4)].getSize();\n      }\n    } else if (this._ssrPostProcess?.inputTexture) {\n      textureSize.width = this._ssrPostProcess.inputTexture.width;\n      textureSize.height = this._ssrPostProcess.inputTexture.height;\n    }\n    return textureSize;\n  }\n  _updateEffectDefines() {\n    const defines = [];\n    if (this._geometryBufferRenderer || this._prePassRenderer) {\n      defines.push(\"#define SSR_SUPPORTED\");\n    }\n    if (this._enableSmoothReflections) {\n      defines.push(\"#define SSRAYTRACE_ENABLE_REFINEMENT\");\n    }\n    if (this._scene.useRightHandedSystem) {\n      defines.push(\"#define SSRAYTRACE_RIGHT_HANDED_SCENE\");\n    }\n    if (this._environmentTexture) {\n      defines.push(\"#define SSR_USE_ENVIRONMENT_CUBE\");\n      if (this._environmentTexture.boundingBoxSize) {\n        defines.push(\"#define SSR_USE_LOCAL_REFLECTIONMAP_CUBIC\");\n      }\n      if (this._environmentTexture.gammaSpace) {\n        defines.push(\"#define SSR_ENVIRONMENT_CUBE_IS_GAMMASPACE\");\n      }\n    }\n    if (this._environmentTextureIsProbe) {\n      defines.push(\"#define SSR_INVERTCUBICMAP\");\n    }\n    if (this._enableAutomaticThicknessComputation) {\n      defines.push(\"#define SSRAYTRACE_USE_BACK_DEPTHBUFFER\");\n    }\n    if (this._attenuateScreenBorders) {\n      defines.push(\"#define SSR_ATTENUATE_SCREEN_BORDERS\");\n    }\n    if (this._attenuateIntersectionDistance) {\n      defines.push(\"#define SSR_ATTENUATE_INTERSECTION_DISTANCE\");\n    }\n    if (this._attenuateIntersectionIterations) {\n      defines.push(\"#define SSR_ATTENUATE_INTERSECTION_NUMITERATIONS\");\n    }\n    if (this._attenuateFacingCamera) {\n      defines.push(\"#define SSR_ATTENUATE_FACING_CAMERA\");\n    }\n    if (this._attenuateBackfaceReflection) {\n      defines.push(\"#define SSR_ATTENUATE_BACKFACE_REFLECTION\");\n    }\n    if (this._clipToFrustum) {\n      defines.push(\"#define SSRAYTRACE_CLIP_TO_FRUSTUM\");\n    }\n    if (this._useBlur()) {\n      defines.push(\"#define SSR_USE_BLUR\");\n    }\n    if (this._debug) {\n      defines.push(\"#define SSRAYTRACE_DEBUG\");\n    }\n    if (this._inputTextureColorIsInGammaSpace) {\n      defines.push(\"#define SSR_INPUT_IS_GAMMA_SPACE\");\n    }\n    if (this._generateOutputInGammaSpace) {\n      defines.push(\"#define SSR_OUTPUT_IS_GAMMA_SPACE\");\n    }\n    if (this._useFresnel) {\n      defines.push(\"#define SSR_BLEND_WITH_FRESNEL\");\n    }\n    if (this._reflectivityThreshold === 0) {\n      defines.push(\"#define SSR_DISABLE_REFLECTIVITY_TEST\");\n    }\n    if (this._geometryBufferRenderer?.generateNormalsInWorldSpace ?? this._prePassRenderer?.generateNormalsInWorldSpace) {\n      defines.push(\"#define SSR_NORMAL_IS_IN_WORLDSPACE\");\n    }\n    if (this._geometryBufferRenderer?.normalsAreUnsigned) {\n      defines.push(\"#define SSR_DECODE_NORMAL\");\n    }\n    this._ssrPostProcess?.updateEffect(defines.join(\"\\n\"));\n  }\n  _buildPipeline() {\n    if (!this.isSupported) {\n      return;\n    }\n    if (!this._isEnabled) {\n      this._isDirty = true;\n      return;\n    }\n    this._isDirty = false;\n    const engine = this._scene.getEngine();\n    this._disposeDepthRenderer();\n    this._disposePostProcesses();\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);\n      // get back cameras to be used to reattach pipeline\n      this._cameras = this._camerasToBeAttached.slice();\n    }\n    this._reset();\n    if (this._enableAutomaticThicknessComputation) {\n      const camera = this._cameras?.[0];\n      if (camera) {\n        this._depthRendererCamera = camera;\n        this._depthRenderer = new DepthRenderer(this._scene, undefined, undefined, undefined, 1, true, \"SSRBackDepth\");\n        this._depthRenderer.clearColor.r = 1e8; // \"infinity\": put a big value because we use the storeCameraSpaceZ mode\n        this._depthRenderer.reverseCulling = true; // we generate depth for the back faces\n        this._depthRenderer.forceDepthWriteTransparentMeshes = this._backfaceForceDepthWriteTransparentMeshes;\n        this._resizeDepthRenderer();\n        camera.customRenderTargets.push(this._depthRenderer.getDepthMap());\n      }\n    }\n    this._createSSRPostProcess();\n    this.addEffect(new PostProcessRenderEffect(engine, this.SSRRenderEffect, () => {\n      return this._ssrPostProcess;\n    }, true));\n    if (this._useBlur()) {\n      this._createBlurAndCombinerPostProcesses();\n      this.addEffect(new PostProcessRenderEffect(engine, this.SSRBlurRenderEffect, () => {\n        return [this._blurPostProcessX, this._blurPostProcessY];\n      }, true));\n      this.addEffect(new PostProcessRenderEffect(engine, this.SSRCombineRenderEffect, () => {\n        return this._blurCombinerPostProcess;\n      }, true));\n    }\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.attachCamerasToRenderPipeline(this._name, this._cameras);\n    }\n  }\n  _resizeDepthRenderer() {\n    if (!this._depthRenderer) {\n      return;\n    }\n    const textureSize = this._getTextureSize();\n    const depthRendererSize = this._depthRenderer.getDepthMap().getSize();\n    const width = Math.floor(textureSize.width / (this._backfaceDepthTextureDownsample + 1));\n    const height = Math.floor(textureSize.height / (this._backfaceDepthTextureDownsample + 1));\n    if (depthRendererSize.width !== width || depthRendererSize.height !== height) {\n      this._depthRenderer.getDepthMap().resize({\n        width,\n        height\n      });\n    }\n  }\n  _disposeDepthRenderer() {\n    if (this._depthRenderer) {\n      if (this._depthRendererCamera) {\n        const idx = this._depthRendererCamera.customRenderTargets.indexOf(this._depthRenderer.getDepthMap()) ?? -1;\n        if (idx !== -1) {\n          this._depthRendererCamera.customRenderTargets.splice(idx, 1);\n        }\n      }\n      this._depthRendererCamera = null;\n      this._depthRenderer.getDepthMap().dispose();\n    }\n    this._depthRenderer = null;\n  }\n  _disposePostProcesses() {\n    for (let i = 0; i < this._cameras.length; i++) {\n      const camera = this._cameras[i];\n      this._ssrPostProcess?.dispose(camera);\n      this._blurPostProcessX?.dispose(camera);\n      this._blurPostProcessY?.dispose(camera);\n      this._blurCombinerPostProcess?.dispose(camera);\n    }\n    this._ssrPostProcess = null;\n    this._blurPostProcessX = null;\n    this._blurPostProcessY = null;\n    this._blurCombinerPostProcess = null;\n  }\n  _createSSRPostProcess() {\n    this._ssrPostProcess = new PostProcess(\"ssr\", \"screenSpaceReflection2\", [\"projection\", \"invProjectionMatrix\", \"view\", \"invView\", \"thickness\", \"reflectionSpecularFalloffExponent\", \"strength\", \"stepSize\", \"maxSteps\", \"roughnessFactor\", \"projectionPixel\", \"nearPlaneZ\", \"maxDistance\", \"selfCollisionNumSkip\", \"vReflectionPosition\", \"vReflectionSize\", \"backSizeFactor\", \"reflectivityThreshold\"], [\"textureSampler\", \"normalSampler\", \"reflectivitySampler\", \"depthSampler\", \"envCubeSampler\", \"backDepthSampler\"], 1.0, null, this._textureType, this._scene.getEngine(), false, \"\", this._textureType);\n    this._updateEffectDefines();\n    this._ssrPostProcess.onApply = effect => {\n      this._resizeDepthRenderer();\n      const geometryBufferRenderer = this._geometryBufferRenderer;\n      const prePassRenderer = this._prePassRenderer;\n      if (!prePassRenderer && !geometryBufferRenderer) {\n        return;\n      }\n      if (geometryBufferRenderer) {\n        const roughnessIndex = geometryBufferRenderer.getTextureIndex(GeometryBufferRenderer.REFLECTIVITY_TEXTURE_TYPE);\n        effect.setTexture(\"normalSampler\", geometryBufferRenderer.getGBuffer().textures[1]);\n        effect.setTexture(\"reflectivitySampler\", geometryBufferRenderer.getGBuffer().textures[roughnessIndex]);\n        effect.setTexture(\"depthSampler\", geometryBufferRenderer.getGBuffer().textures[0]);\n      } else if (prePassRenderer) {\n        const depthIndex = prePassRenderer.getIndex(5);\n        const roughnessIndex = prePassRenderer.getIndex(3);\n        const normalIndex = prePassRenderer.getIndex(6);\n        effect.setTexture(\"normalSampler\", prePassRenderer.getRenderTarget().textures[normalIndex]);\n        effect.setTexture(\"depthSampler\", prePassRenderer.getRenderTarget().textures[depthIndex]);\n        effect.setTexture(\"reflectivitySampler\", prePassRenderer.getRenderTarget().textures[roughnessIndex]);\n      }\n      if (this._enableAutomaticThicknessComputation && this._depthRenderer) {\n        effect.setTexture(\"backDepthSampler\", this._depthRenderer.getDepthMap());\n        effect.setFloat(\"backSizeFactor\", this._backfaceDepthTextureDownsample + 1);\n      }\n      const camera = this._scene.activeCamera;\n      if (!camera) {\n        return;\n      }\n      const viewMatrix = camera.getViewMatrix();\n      const projectionMatrix = camera.getProjectionMatrix();\n      projectionMatrix.invertToRef(TmpVectors.Matrix[0]);\n      viewMatrix.invertToRef(TmpVectors.Matrix[1]);\n      effect.setMatrix(\"projection\", projectionMatrix);\n      effect.setMatrix(\"view\", viewMatrix);\n      effect.setMatrix(\"invView\", TmpVectors.Matrix[1]);\n      effect.setMatrix(\"invProjectionMatrix\", TmpVectors.Matrix[0]);\n      effect.setFloat(\"thickness\", this.thickness);\n      effect.setFloat(\"reflectionSpecularFalloffExponent\", this.reflectionSpecularFalloffExponent);\n      effect.setFloat(\"strength\", this.strength);\n      effect.setFloat(\"stepSize\", this.step);\n      effect.setFloat(\"maxSteps\", this.maxSteps);\n      effect.setFloat(\"roughnessFactor\", this.roughnessFactor);\n      effect.setFloat(\"nearPlaneZ\", camera.minZ);\n      effect.setFloat(\"maxDistance\", this.maxDistance);\n      effect.setFloat(\"selfCollisionNumSkip\", this.selfCollisionNumSkip);\n      effect.setFloat(\"reflectivityThreshold\", this._reflectivityThreshold);\n      const textureSize = this._getTextureSize();\n      Matrix.ScalingToRef(textureSize.width, textureSize.height, 1, TmpVectors.Matrix[2]);\n      projectionMatrix.multiplyToRef(this._scene.getEngine().isWebGPU ? trsWebGPU : trs, TmpVectors.Matrix[3]);\n      TmpVectors.Matrix[3].multiplyToRef(TmpVectors.Matrix[2], TmpVectors.Matrix[4]);\n      effect.setMatrix(\"projectionPixel\", TmpVectors.Matrix[4]);\n      if (this._environmentTexture) {\n        effect.setTexture(\"envCubeSampler\", this._environmentTexture);\n        if (this._environmentTexture.boundingBoxSize) {\n          effect.setVector3(\"vReflectionPosition\", this._environmentTexture.boundingBoxPosition);\n          effect.setVector3(\"vReflectionSize\", this._environmentTexture.boundingBoxSize);\n        }\n      }\n    };\n    this._ssrPostProcess.samples = this.samples;\n    if (!this._forceGeometryBuffer) {\n      this._ssrPostProcess._prePassEffectConfiguration = new ScreenSpaceReflections2Configuration();\n    }\n  }\n  _createBlurAndCombinerPostProcesses() {\n    const engine = this._scene.getEngine();\n    this._blurPostProcessX = new PostProcess(\"SSRblurX\", \"screenSpaceReflection2Blur\", [\"texelOffsetScale\"], [\"textureSampler\"], this._useBlur() ? 1 / (this._ssrDownsample + 1) : 1, null, 2, engine, false, \"\", this._textureType);\n    this._blurPostProcessX.autoClear = false;\n    this._blurPostProcessX.onApplyObservable.add(effect => {\n      const width = this._blurPostProcessX?.inputTexture.width ?? this._scene.getEngine().getRenderWidth();\n      effect.setFloat2(\"texelOffsetScale\", this._blurDispersionStrength / width, 0);\n    });\n    this._blurPostProcessY = new PostProcess(\"SSRblurY\", \"screenSpaceReflection2Blur\", [\"texelOffsetScale\"], [\"textureSampler\"], this._useBlur() ? 1 / (this._blurDownsample + 1) : 1, null, 2, engine, false, \"\", this._textureType);\n    this._blurPostProcessY.autoClear = false;\n    this._blurPostProcessY.onApplyObservable.add(effect => {\n      const height = this._blurPostProcessY?.inputTexture.height ?? this._scene.getEngine().getRenderHeight();\n      effect.setFloat2(\"texelOffsetScale\", 0, this._blurDispersionStrength / height);\n    });\n    const uniformNames = [\"strength\", \"reflectionSpecularFalloffExponent\", \"reflectivityThreshold\"];\n    const samplerNames = [\"textureSampler\", \"mainSampler\", \"reflectivitySampler\"];\n    let defines = \"\";\n    if (this._debug) {\n      defines += \"#define SSRAYTRACE_DEBUG\\n\";\n    }\n    if (this._inputTextureColorIsInGammaSpace) {\n      defines += \"#define SSR_INPUT_IS_GAMMA_SPACE\\n\";\n    }\n    if (this._generateOutputInGammaSpace) {\n      defines += \"#define SSR_OUTPUT_IS_GAMMA_SPACE\\n\";\n    }\n    if (this.useFresnel) {\n      defines += \"#define SSR_BLEND_WITH_FRESNEL\\n\";\n      uniformNames.push(\"projection\", \"invProjectionMatrix\");\n      samplerNames.push(\"depthSampler\", \"normalSampler\");\n    }\n    if (this._reflectivityThreshold === 0) {\n      defines += \"#define SSR_DISABLE_REFLECTIVITY_TEST\";\n    }\n    this._blurCombinerPostProcess = new PostProcess(\"SSRblurCombiner\", \"screenSpaceReflection2BlurCombiner\", uniformNames, samplerNames, this._useBlur() ? 1 / (this._blurDownsample + 1) : 1, null, 1, engine, false, defines, this._textureType);\n    this._blurCombinerPostProcess.autoClear = false;\n    this._blurCombinerPostProcess.onApplyObservable.add(effect => {\n      const geometryBufferRenderer = this._geometryBufferRenderer;\n      const prePassRenderer = this._prePassRenderer;\n      if (!prePassRenderer && !geometryBufferRenderer) {\n        return;\n      }\n      if (prePassRenderer && this._scene.activeCamera?._getFirstPostProcess() === this._ssrPostProcess) {\n        const renderTarget = prePassRenderer.getRenderTarget();\n        if (renderTarget && renderTarget.textures) {\n          effect.setTexture(\"mainSampler\", renderTarget.textures[prePassRenderer.getIndex(4)]);\n        }\n      } else {\n        effect.setTextureFromPostProcess(\"mainSampler\", this._ssrPostProcess);\n      }\n      if (geometryBufferRenderer) {\n        const roughnessIndex = geometryBufferRenderer.getTextureIndex(GeometryBufferRenderer.REFLECTIVITY_TEXTURE_TYPE);\n        effect.setTexture(\"reflectivitySampler\", geometryBufferRenderer.getGBuffer().textures[roughnessIndex]);\n        if (this.useFresnel) {\n          effect.setTexture(\"normalSampler\", geometryBufferRenderer.getGBuffer().textures[1]);\n          effect.setTexture(\"depthSampler\", geometryBufferRenderer.getGBuffer().textures[0]);\n        }\n      } else if (prePassRenderer) {\n        const roughnessIndex = prePassRenderer.getIndex(3);\n        effect.setTexture(\"reflectivitySampler\", prePassRenderer.getRenderTarget().textures[roughnessIndex]);\n        if (this.useFresnel) {\n          const depthIndex = prePassRenderer.getIndex(5);\n          const normalIndex = prePassRenderer.getIndex(6);\n          effect.setTexture(\"normalSampler\", prePassRenderer.getRenderTarget().textures[normalIndex]);\n          effect.setTexture(\"depthSampler\", prePassRenderer.getRenderTarget().textures[depthIndex]);\n        }\n      }\n      effect.setFloat(\"strength\", this.strength);\n      effect.setFloat(\"reflectionSpecularFalloffExponent\", this.reflectionSpecularFalloffExponent);\n      effect.setFloat(\"reflectivityThreshold\", this._reflectivityThreshold);\n      if (this.useFresnel) {\n        const camera = this._scene.activeCamera;\n        if (camera) {\n          const projectionMatrix = camera.getProjectionMatrix();\n          projectionMatrix.invertToRef(TmpVectors.Matrix[0]);\n          effect.setMatrix(\"projection\", projectionMatrix);\n          effect.setMatrix(\"invProjectionMatrix\", TmpVectors.Matrix[0]);\n        }\n      }\n    });\n  }\n  /**\n   * Serializes the rendering pipeline (Used when exporting)\n   * @returns the serialized object\n   */\n  serialize() {\n    const serializationObject = SerializationHelper.Serialize(this);\n    serializationObject.customType = \"SSRRenderingPipeline\";\n    return serializationObject;\n  }\n  /**\n   * Parse the serialized pipeline\n   * @param source Source pipeline.\n   * @param scene The scene to load the pipeline to.\n   * @param rootUrl The URL of the serialized pipeline.\n   * @returns An instantiated pipeline from the serialized object.\n   */\n  static Parse(source, scene, rootUrl) {\n    return SerializationHelper.Parse(() => new SSRRenderingPipeline(source._name, scene, source._ratio), source, scene, rootUrl);\n  }\n}\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"samples\", null);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"maxDistance\", void 0);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"step\", void 0);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"thickness\", void 0);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"strength\", void 0);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"reflectionSpecularFalloffExponent\", void 0);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"maxSteps\", void 0);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"roughnessFactor\", void 0);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"selfCollisionNumSkip\", void 0);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"_reflectivityThreshold\", void 0);\n__decorate([serialize(\"_ssrDownsample\")], SSRRenderingPipeline.prototype, \"_ssrDownsample\", void 0);\n__decorate([serialize()], SSRRenderingPipeline.prototype, \"ssrDownsample\", null);\n__decorate([serialize(\"blurDispersionStrength\")], SSRRenderingPipeline.prototype, \"_blurDispersionStrength\", void 0);\n__decorate([serialize(\"blurDownsample\")], SSRRenderingPipeline.prototype, \"_blurDownsample\", void 0);\n__decorate([serialize(\"enableSmoothReflections\")], SSRRenderingPipeline.prototype, \"_enableSmoothReflections\", void 0);\n__decorate([serialize(\"environmentTexture\")], SSRRenderingPipeline.prototype, \"_environmentTexture\", void 0);\n__decorate([serialize(\"environmentTextureIsProbe\")], SSRRenderingPipeline.prototype, \"_environmentTextureIsProbe\", void 0);\n__decorate([serialize(\"attenuateScreenBorders\")], SSRRenderingPipeline.prototype, \"_attenuateScreenBorders\", void 0);\n__decorate([serialize(\"attenuateIntersectionDistance\")], SSRRenderingPipeline.prototype, \"_attenuateIntersectionDistance\", void 0);\n__decorate([serialize(\"attenuateIntersectionIterations\")], SSRRenderingPipeline.prototype, \"_attenuateIntersectionIterations\", void 0);\n__decorate([serialize(\"attenuateFacingCamera\")], SSRRenderingPipeline.prototype, \"_attenuateFacingCamera\", void 0);\n__decorate([serialize(\"attenuateBackfaceReflection\")], SSRRenderingPipeline.prototype, \"_attenuateBackfaceReflection\", void 0);\n__decorate([serialize(\"clipToFrustum\")], SSRRenderingPipeline.prototype, \"_clipToFrustum\", void 0);\n__decorate([serialize(\"useFresnel\")], SSRRenderingPipeline.prototype, \"_useFresnel\", void 0);\n__decorate([serialize(\"enableAutomaticThicknessComputation\")], SSRRenderingPipeline.prototype, \"_enableAutomaticThicknessComputation\", void 0);\n__decorate([serialize(\"backfaceDepthTextureDownsample\")], SSRRenderingPipeline.prototype, \"_backfaceDepthTextureDownsample\", void 0);\n__decorate([serialize(\"backfaceForceDepthWriteTransparentMeshes\")], SSRRenderingPipeline.prototype, \"_backfaceForceDepthWriteTransparentMeshes\", void 0);\n__decorate([serialize(\"isEnabled\")], SSRRenderingPipeline.prototype, \"_isEnabled\", void 0);\n__decorate([serialize(\"inputTextureColorIsInGammaSpace\")], SSRRenderingPipeline.prototype, \"_inputTextureColorIsInGammaSpace\", void 0);\n__decorate([serialize(\"generateOutputInGammaSpace\")], SSRRenderingPipeline.prototype, \"_generateOutputInGammaSpace\", void 0);\n__decorate([serialize(\"debug\")], SSRRenderingPipeline.prototype, \"_debug\", void 0);\nRegisterClass(\"BABYLON.SSRRenderingPipeline\", SSRRenderingPipeline);\n//# sourceMappingURL=ssrRenderingPipeline.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}