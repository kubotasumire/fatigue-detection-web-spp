{"ast":null,"code":"import { __decorate } from \"../../tslib.es6.js\";\nimport { Observable } from \"../../Misc/observable.js\";\nimport { Tools } from \"../../Misc/tools.js\";\nimport { Logger } from \"../../Misc/logger.js\";\nimport { Texture } from \"../../Materials/Textures/texture.js\";\nimport \"../../Engines/Extensions/engine.videoTexture.js\";\nimport \"../../Engines/Extensions/engine.dynamicTexture.js\";\nimport { serialize } from \"../../Misc/decorators.js\";\nimport { RegisterClass } from \"../../Misc/typeStore.js\";\nfunction removeSource(video) {\n  // Remove any <source> elements, etc.\n  while (video.firstChild) {\n    video.removeChild(video.firstChild);\n  }\n  // detach srcObject\n  video.srcObject = null;\n  // Set a blank src (https://html.spec.whatwg.org/multipage/media.html#best-practices-for-authors-using-media-elements)\n  video.src = \"\";\n  // Prevent non-important errors maybe (https://twitter.com/beraliv/status/1205214277956775936)\n  video.removeAttribute(\"src\");\n}\n/**\n * If you want to display a video in your scene, this is the special texture for that.\n * This special texture works similar to other textures, with the exception of a few parameters.\n * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/videoTexture\n */\nexport class VideoTexture extends Texture {\n  /**\n   * Event triggered when a dom action is required by the user to play the video.\n   * This happens due to recent changes in browser policies preventing video to auto start.\n   */\n  get onUserActionRequestedObservable() {\n    if (!this._onUserActionRequestedObservable) {\n      this._onUserActionRequestedObservable = new Observable();\n    }\n    return this._onUserActionRequestedObservable;\n  }\n  _processError(reason) {\n    this._errorFound = true;\n    if (this._onError) {\n      this._onError(reason?.message);\n    } else {\n      Logger.Error(reason?.message);\n    }\n  }\n  _handlePlay() {\n    this._errorFound = false;\n    this.video.play().catch(reason => {\n      if (reason?.name === \"NotAllowedError\") {\n        if (this._onUserActionRequestedObservable && this._onUserActionRequestedObservable.hasObservers()) {\n          this._onUserActionRequestedObservable.notifyObservers(this);\n          return;\n        } else if (!this.video.muted) {\n          Logger.Warn(\"Unable to autoplay a video with sound. Trying again with muted turned true\");\n          this.video.muted = true;\n          this._errorFound = false;\n          this.video.play().catch(otherReason => {\n            this._processError(otherReason);\n          });\n          return;\n        }\n      }\n      this._processError(reason);\n    });\n  }\n  /**\n   * Creates a video texture.\n   * If you want to display a video in your scene, this is the special texture for that.\n   * This special texture works similar to other textures, with the exception of a few parameters.\n   * @see https://doc.babylonjs.com/features/featuresDeepDive/materials/using/videoTexture\n   * @param name optional name, will detect from video source, if not defined\n   * @param src can be used to provide an url, array of urls or an already setup HTML video element.\n   * @param scene is obviously the current scene.\n   * @param generateMipMaps can be used to turn on mipmaps (Can be expensive for videoTextures because they are often updated).\n   * @param invertY is false by default but can be used to invert video on Y axis\n   * @param samplingMode controls the sampling method and is set to TRILINEAR_SAMPLINGMODE by default\n   * @param settings allows finer control over video usage\n   * @param onError defines a callback triggered when an error occurred during the loading session\n   * @param format defines the texture format to use (Engine.TEXTUREFORMAT_RGBA by default)\n   */\n  constructor(name, src, scene, generateMipMaps = false, invertY = false, samplingMode = Texture.TRILINEAR_SAMPLINGMODE, settings = {}, onError, format = 5) {\n    super(null, scene, !generateMipMaps, invertY);\n    this._externalTexture = null;\n    this._onUserActionRequestedObservable = null;\n    this._stillImageCaptured = false;\n    this._displayingPosterTexture = false;\n    this._frameId = -1;\n    this._currentSrc = null;\n    this._errorFound = false;\n    /**\n     * Serialize the flag to define this texture as a video texture\n     */\n    this.isVideo = true;\n    this._resizeInternalTexture = () => {\n      // Cleanup the old texture before replacing it\n      if (this._texture != null) {\n        this._texture.dispose();\n      }\n      if (!this._getEngine().needPOTTextures || Tools.IsExponentOfTwo(this.video.videoWidth) && Tools.IsExponentOfTwo(this.video.videoHeight)) {\n        this.wrapU = Texture.WRAP_ADDRESSMODE;\n        this.wrapV = Texture.WRAP_ADDRESSMODE;\n      } else {\n        this.wrapU = Texture.CLAMP_ADDRESSMODE;\n        this.wrapV = Texture.CLAMP_ADDRESSMODE;\n        this._generateMipMaps = false;\n      }\n      this._texture = this._getEngine().createDynamicTexture(this.video.videoWidth, this.video.videoHeight, this._generateMipMaps, this.samplingMode);\n      this._texture.format = this._format ?? 5;\n      // Reset the frame ID and update the new texture to ensure it pulls in the current video frame\n      this._frameId = -1;\n      this._updateInternalTexture();\n    };\n    this._createInternalTexture = () => {\n      if (this._texture != null) {\n        if (this._displayingPosterTexture) {\n          this._displayingPosterTexture = false;\n        } else {\n          return;\n        }\n      }\n      this.video.addEventListener(\"resize\", this._resizeInternalTexture);\n      this._resizeInternalTexture();\n      if (!this.video.autoplay && !this._settings.poster && !this._settings.independentVideoSource) {\n        const oldHandler = this.video.onplaying;\n        const oldMuted = this.video.muted;\n        this.video.muted = true;\n        this.video.onplaying = () => {\n          this.video.muted = oldMuted;\n          this.video.onplaying = oldHandler;\n          this._updateInternalTexture();\n          if (!this._errorFound) {\n            this.video.pause();\n          }\n          if (this.onLoadObservable.hasObservers()) {\n            this.onLoadObservable.notifyObservers(this);\n          }\n        };\n        this._handlePlay();\n      } else {\n        this._updateInternalTexture();\n        if (this.onLoadObservable.hasObservers()) {\n          this.onLoadObservable.notifyObservers(this);\n        }\n      }\n    };\n    this._reset = () => {\n      if (this._texture == null) {\n        return;\n      }\n      if (!this._displayingPosterTexture) {\n        this._texture.dispose();\n        this._texture = null;\n      }\n    };\n    this._updateInternalTexture = () => {\n      if (this._texture == null) {\n        return;\n      }\n      if (this.video.readyState < this.video.HAVE_CURRENT_DATA) {\n        return;\n      }\n      if (this._displayingPosterTexture) {\n        return;\n      }\n      const frameId = this.getScene().getFrameId();\n      if (this._frameId === frameId) {\n        return;\n      }\n      this._frameId = frameId;\n      this._getEngine().updateVideoTexture(this._texture, this._externalTexture ? this._externalTexture : this.video, this._invertY);\n    };\n    this._settings = {\n      autoPlay: true,\n      loop: true,\n      autoUpdateTexture: true,\n      ...settings\n    };\n    this._onError = onError;\n    this._generateMipMaps = generateMipMaps;\n    this._initialSamplingMode = samplingMode;\n    this.autoUpdateTexture = this._settings.autoUpdateTexture;\n    this._currentSrc = src;\n    this.name = name || this._getName(src);\n    this.video = this._getVideo(src);\n    if (this._engine?.createExternalTexture) {\n      this._externalTexture = this._engine.createExternalTexture(this.video);\n    }\n    if (!this._settings.independentVideoSource) {\n      if (this._settings.poster) {\n        this.video.poster = this._settings.poster;\n      }\n      if (this._settings.autoPlay !== undefined) {\n        this.video.autoplay = this._settings.autoPlay;\n      }\n      if (this._settings.loop !== undefined) {\n        this.video.loop = this._settings.loop;\n      }\n      if (this._settings.muted !== undefined) {\n        this.video.muted = this._settings.muted;\n      }\n      this.video.setAttribute(\"playsinline\", \"\");\n      this.video.addEventListener(\"paused\", this._updateInternalTexture);\n      this.video.addEventListener(\"seeked\", this._updateInternalTexture);\n      this.video.addEventListener(\"loadeddata\", this._updateInternalTexture);\n      this.video.addEventListener(\"emptied\", this._reset);\n      if (this._settings.autoPlay) {\n        this._handlePlay();\n      }\n    }\n    this._createInternalTextureOnEvent = this._settings.poster && !this._settings.autoPlay ? \"play\" : \"canplay\";\n    this.video.addEventListener(this._createInternalTextureOnEvent, this._createInternalTexture);\n    this._format = format;\n    const videoHasEnoughData = this.video.readyState >= this.video.HAVE_CURRENT_DATA;\n    if (this._settings.poster && (!this._settings.autoPlay || !videoHasEnoughData)) {\n      this._texture = this._getEngine().createTexture(this._settings.poster, false, !this.invertY, scene);\n      this._displayingPosterTexture = true;\n    } else if (videoHasEnoughData) {\n      this._createInternalTexture();\n    }\n  }\n  /**\n   * Get the current class name of the video texture useful for serialization or dynamic coding.\n   * @returns \"VideoTexture\"\n   */\n  getClassName() {\n    return \"VideoTexture\";\n  }\n  _getName(src) {\n    if (src instanceof HTMLVideoElement) {\n      return src.currentSrc;\n    }\n    if (typeof src === \"object\") {\n      return src.toString();\n    }\n    return src;\n  }\n  _getVideo(src) {\n    if (src.isNative) {\n      return src;\n    }\n    if (src instanceof HTMLVideoElement) {\n      Tools.SetCorsBehavior(src.currentSrc, src);\n      return src;\n    }\n    const video = document.createElement(\"video\");\n    if (typeof src === \"string\") {\n      Tools.SetCorsBehavior(src, video);\n      video.src = src;\n    } else {\n      Tools.SetCorsBehavior(src[0], video);\n      src.forEach(url => {\n        const source = document.createElement(\"source\");\n        source.src = url;\n        video.appendChild(source);\n      });\n    }\n    this.onDisposeObservable.addOnce(() => {\n      removeSource(video);\n    });\n    return video;\n  }\n  /**\n   * @internal Internal method to initiate `update`.\n   */\n  _rebuild() {\n    this.update();\n  }\n  /**\n   * Update Texture in the `auto` mode. Does not do anything if `settings.autoUpdateTexture` is false.\n   */\n  update() {\n    if (!this.autoUpdateTexture) {\n      // Expecting user to call `updateTexture` manually\n      return;\n    }\n    this.updateTexture(true);\n  }\n  /**\n   * Update Texture in `manual` mode. Does not do anything if not visible or paused.\n   * @param isVisible Visibility state, detected by user using `scene.getActiveMeshes()` or otherwise.\n   */\n  updateTexture(isVisible) {\n    if (!isVisible) {\n      return;\n    }\n    if (this.video.paused && this._stillImageCaptured) {\n      return;\n    }\n    this._stillImageCaptured = true;\n    this._updateInternalTexture();\n  }\n  /**\n   * Get the underlying external texture (if supported by the current engine, else null)\n   */\n  get externalTexture() {\n    return this._externalTexture;\n  }\n  /**\n   * Change video content. Changing video instance or setting multiple urls (as in constructor) is not supported.\n   * @param url New url.\n   */\n  updateURL(url) {\n    this.video.src = url;\n    this._currentSrc = url;\n  }\n  /**\n   * Clones the texture.\n   * @returns the cloned texture\n   */\n  clone() {\n    return new VideoTexture(this.name, this._currentSrc, this.getScene(), this._generateMipMaps, this.invertY, this.samplingMode, this._settings);\n  }\n  /**\n   * Dispose the texture and release its associated resources.\n   */\n  dispose() {\n    super.dispose();\n    this._currentSrc = null;\n    if (this._onUserActionRequestedObservable) {\n      this._onUserActionRequestedObservable.clear();\n      this._onUserActionRequestedObservable = null;\n    }\n    this.video.removeEventListener(this._createInternalTextureOnEvent, this._createInternalTexture);\n    if (!this._settings.independentVideoSource) {\n      this.video.removeEventListener(\"paused\", this._updateInternalTexture);\n      this.video.removeEventListener(\"seeked\", this._updateInternalTexture);\n      this.video.removeEventListener(\"loadeddata\", this._updateInternalTexture);\n      this.video.removeEventListener(\"emptied\", this._reset);\n      this.video.removeEventListener(\"resize\", this._resizeInternalTexture);\n      this.video.pause();\n    }\n    this._externalTexture?.dispose();\n  }\n  /**\n   * Creates a video texture straight from a stream.\n   * @param scene Define the scene the texture should be created in\n   * @param stream Define the stream the texture should be created from\n   * @param constraints video constraints\n   * @param invertY Defines if the video should be stored with invert Y set to true (true by default)\n   * @returns The created video texture as a promise\n   */\n  static CreateFromStreamAsync(scene, stream, constraints, invertY = true) {\n    const video = scene.getEngine().createVideoElement(constraints);\n    if (scene.getEngine()._badOS) {\n      // Yes... I know and I hope to remove it soon...\n      document.body.appendChild(video);\n      video.style.transform = \"scale(0.0001, 0.0001)\";\n      video.style.opacity = \"0\";\n      video.style.position = \"fixed\";\n      video.style.bottom = \"0px\";\n      video.style.right = \"0px\";\n    }\n    video.setAttribute(\"autoplay\", \"\");\n    video.setAttribute(\"muted\", \"true\");\n    video.setAttribute(\"playsinline\", \"\");\n    video.muted = true;\n    if (video.isNative) {\n      // No additional configuration needed for native\n    } else if (video.mozSrcObject !== undefined) {\n      // hack for Firefox < 19\n      video.mozSrcObject = stream;\n    } else {\n      if (typeof video.srcObject == \"object\") {\n        video.srcObject = stream;\n      } else {\n        // older API. See https://developer.mozilla.org/en-US/docs/Web/API/URL/createObjectURL#using_object_urls_for_media_streams\n        video.src = window.URL && window.URL.createObjectURL(stream);\n      }\n    }\n    return new Promise(resolve => {\n      const onPlaying = () => {\n        const videoTexture = new VideoTexture(\"video\", video, scene, true, invertY, undefined, undefined, undefined, 4);\n        if (scene.getEngine()._badOS) {\n          videoTexture.onDisposeObservable.addOnce(() => {\n            video.remove();\n          });\n        }\n        videoTexture.onDisposeObservable.addOnce(() => {\n          removeSource(video);\n        });\n        resolve(videoTexture);\n        video.removeEventListener(\"playing\", onPlaying);\n      };\n      video.addEventListener(\"playing\", onPlaying);\n      video.play();\n    });\n  }\n  /**\n   * Creates a video texture straight from your WebCam video feed.\n   * @param scene Define the scene the texture should be created in\n   * @param constraints Define the constraints to use to create the web cam feed from WebRTC\n   * @param audioConstaints Define the audio constraints to use to create the web cam feed from WebRTC\n   * @param invertY Defines if the video should be stored with invert Y set to true (true by default)\n   * @returns The created video texture as a promise\n   */\n  static async CreateFromWebCamAsync(scene, constraints, audioConstaints = false, invertY = true) {\n    if (navigator.mediaDevices) {\n      const stream = await navigator.mediaDevices.getUserMedia({\n        video: constraints,\n        audio: audioConstaints\n      });\n      const videoTexture = await this.CreateFromStreamAsync(scene, stream, constraints, invertY);\n      videoTexture.onDisposeObservable.addOnce(() => {\n        stream.getTracks().forEach(track => {\n          track.stop();\n        });\n      });\n      return videoTexture;\n    }\n    return Promise.reject(\"No support for userMedia on this device\");\n  }\n  /**\n   * Creates a video texture straight from your WebCam video feed.\n   * @param scene Defines the scene the texture should be created in\n   * @param onReady Defines a callback to triggered once the texture will be ready\n   * @param constraints Defines the constraints to use to create the web cam feed from WebRTC\n   * @param audioConstaints Defines the audio constraints to use to create the web cam feed from WebRTC\n   * @param invertY Defines if the video should be stored with invert Y set to true (true by default)\n   */\n  static CreateFromWebCam(scene, onReady, constraints, audioConstaints = false, invertY = true) {\n    this.CreateFromWebCamAsync(scene, constraints, audioConstaints, invertY).then(function (videoTexture) {\n      if (onReady) {\n        onReady(videoTexture);\n      }\n    }).catch(function (err) {\n      Logger.Error(err.name);\n    });\n  }\n}\n__decorate([serialize(\"settings\")], VideoTexture.prototype, \"_settings\", void 0);\n__decorate([serialize(\"src\")], VideoTexture.prototype, \"_currentSrc\", void 0);\n__decorate([serialize()], VideoTexture.prototype, \"isVideo\", void 0);\nTexture._CreateVideoTexture = (name, src, scene, generateMipMaps = false, invertY = false, samplingMode = Texture.TRILINEAR_SAMPLINGMODE, settings = {}, onError, format = 5) => {\n  return new VideoTexture(name, src, scene, generateMipMaps, invertY, samplingMode, settings, onError, format);\n};\n// Some exporters relies on Tools.Instantiate\nRegisterClass(\"BABYLON.VideoTexture\", VideoTexture);\n//# sourceMappingURL=videoTexture.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}