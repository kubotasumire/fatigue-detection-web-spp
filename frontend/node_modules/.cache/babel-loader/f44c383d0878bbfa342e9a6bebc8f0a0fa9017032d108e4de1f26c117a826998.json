{"ast":null,"code":"import { __decorate } from \"../../../tslib.es6.js\";\nimport { serialize, serializeAsTexture } from \"../../../Misc/decorators.js\";\nimport { SerializationHelper } from \"../../../Misc/decorators.serialization.js\";\nimport { Logger } from \"../../../Misc/logger.js\";\nimport { Vector2, Vector3, Matrix, Vector4 } from \"../../../Maths/math.vector.js\";\nimport { Scalar } from \"../../../Maths/math.scalar.js\";\nimport { Texture } from \"../../../Materials/Textures/texture.js\";\nimport { PostProcess } from \"../../../PostProcesses/postProcess.js\";\nimport { PostProcessRenderPipeline } from \"../../../PostProcesses/RenderPipeline/postProcessRenderPipeline.js\";\nimport { PostProcessRenderEffect } from \"../../../PostProcesses/RenderPipeline/postProcessRenderEffect.js\";\nimport { BlurPostProcess } from \"../../../PostProcesses/blurPostProcess.js\";\nimport { FxaaPostProcess } from \"../../../PostProcesses/fxaaPostProcess.js\";\nimport { RegisterClass } from \"../../../Misc/typeStore.js\";\nimport { MotionBlurPostProcess } from \"../../motionBlurPostProcess.js\";\nimport { ScreenSpaceReflectionPostProcess } from \"../../screenSpaceReflectionPostProcess.js\";\nimport \"../../../PostProcesses/RenderPipeline/postProcessRenderPipelineManagerSceneComponent.js\";\nimport \"../../../Shaders/standard.fragment.js\";\n/**\n * Standard rendering pipeline\n * Default pipeline should be used going forward but the standard pipeline will be kept for backwards compatibility.\n * @see https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/standardRenderingPipeline\n */\nexport class StandardRenderingPipeline extends PostProcessRenderPipeline {\n  /**\n   * Gets the overall exposure used by the pipeline\n   */\n  get exposure() {\n    return this._fixedExposure;\n  }\n  /**\n   * Sets the overall exposure used by the pipeline\n   */\n  set exposure(value) {\n    this._fixedExposure = value;\n    this._currentExposure = value;\n  }\n  /**\n   * Gets whether or not the exposure of the overall pipeline should be automatically adjusted by the HDR post-process\n   */\n  get hdrAutoExposure() {\n    return this._hdrAutoExposure;\n  }\n  /**\n   * Sets whether or not the exposure of the overall pipeline should be automatically adjusted by the HDR post-process\n   */\n  set hdrAutoExposure(value) {\n    this._hdrAutoExposure = value;\n    if (this.hdrPostProcess) {\n      const defines = [\"#define HDR\"];\n      if (value) {\n        defines.push(\"#define AUTO_EXPOSURE\");\n      }\n      this.hdrPostProcess.updateEffect(defines.join(\"\\n\"));\n    }\n  }\n  /**\n   * Gets how much the image is blurred by the movement while using the motion blur post-process\n   */\n  get motionStrength() {\n    return this._motionStrength;\n  }\n  /**\n   * Sets how much the image is blurred by the movement while using the motion blur post-process\n   */\n  set motionStrength(strength) {\n    this._motionStrength = strength;\n    if (this._isObjectBasedMotionBlur && this.motionBlurPostProcess) {\n      this.motionBlurPostProcess.motionStrength = strength;\n    }\n  }\n  /**\n   * Gets whether or not the motion blur post-process is object based or screen based.\n   */\n  get objectBasedMotionBlur() {\n    return this._isObjectBasedMotionBlur;\n  }\n  /**\n   * Sets whether or not the motion blur post-process should be object based or screen based\n   */\n  set objectBasedMotionBlur(value) {\n    const shouldRebuild = this._isObjectBasedMotionBlur !== value;\n    this._isObjectBasedMotionBlur = value;\n    if (shouldRebuild) {\n      this._buildPipeline();\n    }\n  }\n  /**\n   * @ignore\n   * Specifies if the bloom pipeline is enabled\n   */\n  get BloomEnabled() {\n    return this._bloomEnabled;\n  }\n  set BloomEnabled(enabled) {\n    if (this._bloomEnabled === enabled) {\n      return;\n    }\n    this._bloomEnabled = enabled;\n    this._buildPipeline();\n  }\n  /**\n   * @ignore\n   * Specifies if the depth of field pipeline is enabled\n   */\n  get DepthOfFieldEnabled() {\n    return this._depthOfFieldEnabled;\n  }\n  set DepthOfFieldEnabled(enabled) {\n    if (this._depthOfFieldEnabled === enabled) {\n      return;\n    }\n    this._depthOfFieldEnabled = enabled;\n    this._buildPipeline();\n  }\n  /**\n   * @ignore\n   * Specifies if the lens flare pipeline is enabled\n   */\n  get LensFlareEnabled() {\n    return this._lensFlareEnabled;\n  }\n  set LensFlareEnabled(enabled) {\n    if (this._lensFlareEnabled === enabled) {\n      return;\n    }\n    this._lensFlareEnabled = enabled;\n    this._buildPipeline();\n  }\n  /**\n   * @ignore\n   * Specifies if the HDR pipeline is enabled\n   */\n  get HDREnabled() {\n    return this._hdrEnabled;\n  }\n  set HDREnabled(enabled) {\n    if (this._hdrEnabled === enabled) {\n      return;\n    }\n    this._hdrEnabled = enabled;\n    this._buildPipeline();\n  }\n  /**\n   * @ignore\n   * Specifies if the volumetric lights scattering effect is enabled\n   */\n  get VLSEnabled() {\n    return this._vlsEnabled;\n  }\n  // eslint-disable-next-line @typescript-eslint/naming-convention\n  set VLSEnabled(enabled) {\n    if (this._vlsEnabled === enabled) {\n      return;\n    }\n    if (enabled) {\n      const geometry = this._scene.enableGeometryBufferRenderer();\n      if (!geometry) {\n        Logger.Warn(\"Geometry renderer is not supported, cannot create volumetric lights in Standard Rendering Pipeline\");\n        return;\n      }\n    }\n    this._vlsEnabled = enabled;\n    this._buildPipeline();\n  }\n  /**\n   * @ignore\n   * Specifies if the motion blur effect is enabled\n   */\n  get MotionBlurEnabled() {\n    return this._motionBlurEnabled;\n  }\n  set MotionBlurEnabled(enabled) {\n    if (this._motionBlurEnabled === enabled) {\n      return;\n    }\n    this._motionBlurEnabled = enabled;\n    this._buildPipeline();\n  }\n  /**\n   * Specifies if anti-aliasing is enabled\n   */\n  get fxaaEnabled() {\n    return this._fxaaEnabled;\n  }\n  set fxaaEnabled(enabled) {\n    if (this._fxaaEnabled === enabled) {\n      return;\n    }\n    this._fxaaEnabled = enabled;\n    this._buildPipeline();\n  }\n  /**\n   * Specifies if screen space reflections are enabled.\n   */\n  get screenSpaceReflectionsEnabled() {\n    return this._screenSpaceReflectionsEnabled;\n  }\n  set screenSpaceReflectionsEnabled(enabled) {\n    if (this._screenSpaceReflectionsEnabled === enabled) {\n      return;\n    }\n    this._screenSpaceReflectionsEnabled = enabled;\n    this._buildPipeline();\n  }\n  /**\n   * Specifies the number of steps used to calculate the volumetric lights\n   * Typically in interval [50, 200]\n   */\n  get volumetricLightStepsCount() {\n    return this._volumetricLightStepsCount;\n  }\n  set volumetricLightStepsCount(count) {\n    if (this.volumetricLightPostProcess) {\n      this.volumetricLightPostProcess.updateEffect(\"#define VLS\\n#define NB_STEPS \" + count.toFixed(1));\n    }\n    this._volumetricLightStepsCount = count;\n  }\n  /**\n   * Specifies the number of samples used for the motion blur effect\n   * Typically in interval [16, 64]\n   */\n  get motionBlurSamples() {\n    return this._motionBlurSamples;\n  }\n  set motionBlurSamples(samples) {\n    if (this.motionBlurPostProcess) {\n      if (this._isObjectBasedMotionBlur) {\n        this.motionBlurPostProcess.motionBlurSamples = samples;\n      } else {\n        this.motionBlurPostProcess.updateEffect(\"#define MOTION_BLUR\\n#define MAX_MOTION_SAMPLES \" + samples.toFixed(1));\n      }\n    }\n    this._motionBlurSamples = samples;\n  }\n  /**\n   * Specifies MSAA sample count, setting this to 4 will provide 4x anti aliasing. (default: 1)\n   */\n  get samples() {\n    return this._samples;\n  }\n  set samples(sampleCount) {\n    if (this._samples === sampleCount) {\n      return;\n    }\n    this._samples = sampleCount;\n    this._buildPipeline();\n  }\n  /**\n   * Default pipeline should be used going forward but the standard pipeline will be kept for backwards compatibility.\n   * @constructor\n   * @param name The rendering pipeline name\n   * @param scene The scene linked to this pipeline\n   * @param ratio The size of the postprocesses (0.5 means that your postprocess will have a width = canvas.width 0.5 and a height = canvas.height 0.5)\n   * @param originalPostProcess the custom original color post-process. Must be \"reusable\". Can be null.\n   * @param cameras The array of cameras that the rendering pipeline will be attached to\n   */\n  constructor(name, scene, ratio, originalPostProcess = null, cameras) {\n    super(scene.getEngine(), name);\n    /**\n     * Post-process used to down scale an image x4\n     */\n    this.downSampleX4PostProcess = null;\n    /**\n     * Post-process used to calculate the illuminated surfaces controlled by a threshold\n     */\n    this.brightPassPostProcess = null;\n    /**\n     * Post-process array storing all the horizontal blur post-processes used by the pipeline\n     */\n    this.blurHPostProcesses = [];\n    /**\n     * Post-process array storing all the vertical blur post-processes used by the pipeline\n     */\n    this.blurVPostProcesses = [];\n    /**\n     * Post-process used to add colors of 2 textures (typically brightness + real scene color)\n     */\n    this.textureAdderPostProcess = null;\n    /**\n     * Post-process used to create volumetric lighting effect\n     */\n    this.volumetricLightPostProcess = null;\n    /**\n     * Post-process used to smooth the previous volumetric light post-process on the X axis\n     */\n    this.volumetricLightSmoothXPostProcess = null;\n    /**\n     * Post-process used to smooth the previous volumetric light post-process on the Y axis\n     */\n    this.volumetricLightSmoothYPostProcess = null;\n    /**\n     * Post-process used to merge the volumetric light effect and the real scene color\n     */\n    this.volumetricLightMergePostProces = null;\n    /**\n     * Post-process used to store the final volumetric light post-process (attach/detach for debug purpose)\n     */\n    this.volumetricLightFinalPostProcess = null;\n    /**\n     * Base post-process used to calculate the average luminance of the final image for HDR\n     */\n    this.luminancePostProcess = null;\n    /**\n     * Post-processes used to create down sample post-processes in order to get\n     * the average luminance of the final image for HDR\n     * Array of length \"StandardRenderingPipeline.LuminanceSteps\"\n     */\n    this.luminanceDownSamplePostProcesses = [];\n    /**\n     * Post-process used to create a HDR effect (light adaptation)\n     */\n    this.hdrPostProcess = null;\n    /**\n     * Post-process used to store the final texture adder post-process (attach/detach for debug purpose)\n     */\n    this.textureAdderFinalPostProcess = null;\n    /**\n     * Post-process used to store the final lens flare post-process (attach/detach for debug purpose)\n     */\n    this.lensFlareFinalPostProcess = null;\n    /**\n     * Post-process used to merge the final HDR post-process and the real scene color\n     */\n    this.hdrFinalPostProcess = null;\n    /**\n     * Post-process used to create a lens flare effect\n     */\n    this.lensFlarePostProcess = null;\n    /**\n     * Post-process that merges the result of the lens flare post-process and the real scene color\n     */\n    this.lensFlareComposePostProcess = null;\n    /**\n     * Post-process used to create a motion blur effect\n     */\n    this.motionBlurPostProcess = null;\n    /**\n     * Post-process used to create a depth of field effect\n     */\n    this.depthOfFieldPostProcess = null;\n    /**\n     * The Fast Approximate Anti-Aliasing post process which attempts to remove aliasing from an image.\n     */\n    this.fxaaPostProcess = null;\n    /**\n     * Post-process used to simulate realtime reflections using the screen space and geometry renderer.\n     */\n    this.screenSpaceReflectionPostProcess = null;\n    // Values\n    /**\n     * Represents the brightness threshold in order to configure the illuminated surfaces\n     */\n    this.brightThreshold = 1.0;\n    /**\n     * Configures the blur intensity used for surexposed surfaces are highlighted surfaces (light halo)\n     */\n    this.blurWidth = 512.0;\n    /**\n     * Sets if the blur for highlighted surfaces must be only horizontal\n     */\n    this.horizontalBlur = false;\n    /**\n     * Texture used typically to simulate \"dirty\" on camera lens\n     */\n    this.lensTexture = null;\n    /**\n     * Represents the offset coefficient based on Rayleigh principle. Typically in interval [-0.2, 0.2]\n     */\n    this.volumetricLightCoefficient = 0.2;\n    /**\n     * The overall power of volumetric lights, typically in interval [0, 10] maximum\n     */\n    this.volumetricLightPower = 4.0;\n    /**\n     * Used the set the blur intensity to smooth the volumetric lights\n     */\n    this.volumetricLightBlurScale = 64.0;\n    /**\n     * Light (spot or directional) used to generate the volumetric lights rays\n     * The source light must have a shadow generate so the pipeline can get its\n     * depth map\n     */\n    this.sourceLight = null;\n    /**\n     * For eye adaptation, represents the minimum luminance the eye can see\n     */\n    this.hdrMinimumLuminance = 1.0;\n    /**\n     * For eye adaptation, represents the decrease luminance speed\n     */\n    this.hdrDecreaseRate = 0.5;\n    /**\n     * For eye adaptation, represents the increase luminance speed\n     */\n    this.hdrIncreaseRate = 0.5;\n    /**\n     * Lens color texture used by the lens flare effect. Mandatory if lens flare effect enabled\n     */\n    this.lensColorTexture = null;\n    /**\n     * The overall strength for the lens flare effect\n     */\n    this.lensFlareStrength = 20.0;\n    /**\n     * Dispersion coefficient for lens flare ghosts\n     */\n    this.lensFlareGhostDispersal = 1.4;\n    /**\n     * Main lens flare halo width\n     */\n    this.lensFlareHaloWidth = 0.7;\n    /**\n     * Based on the lens distortion effect, defines how much the lens flare result\n     * is distorted\n     */\n    this.lensFlareDistortionStrength = 16.0;\n    /**\n     * Configures the blur intensity used for for lens flare (halo)\n     */\n    this.lensFlareBlurWidth = 512.0;\n    /**\n     * Lens star texture must be used to simulate rays on the flares and is available\n     * in the documentation\n     */\n    this.lensStarTexture = null;\n    /**\n     * As the \"lensTexture\" (can be the same texture or different), it is used to apply the lens\n     * flare effect by taking account of the dirt texture\n     */\n    this.lensFlareDirtTexture = null;\n    /**\n     * Represents the focal length for the depth of field effect\n     */\n    this.depthOfFieldDistance = 10.0;\n    /**\n     * Represents the blur intensity for the blurred part of the depth of field effect\n     */\n    this.depthOfFieldBlurWidth = 64.0;\n    /**\n     * List of animations for the pipeline (IAnimatable implementation)\n     */\n    this.animations = [];\n    this._currentDepthOfFieldSource = null;\n    this._fixedExposure = 1.0;\n    this._currentExposure = 1.0;\n    this._hdrAutoExposure = false;\n    this._hdrCurrentLuminance = 1.0;\n    this._motionStrength = 1.0;\n    this._isObjectBasedMotionBlur = false;\n    this._camerasToBeAttached = [];\n    // Getters and setters\n    this._bloomEnabled = false;\n    this._depthOfFieldEnabled = false;\n    this._vlsEnabled = false;\n    this._lensFlareEnabled = false;\n    this._hdrEnabled = false;\n    this._motionBlurEnabled = false;\n    this._fxaaEnabled = false;\n    this._screenSpaceReflectionsEnabled = false;\n    this._motionBlurSamples = 64.0;\n    this._volumetricLightStepsCount = 50.0;\n    this._samples = 1;\n    this._cameras = cameras || scene.cameras;\n    this._cameras = this._cameras.slice();\n    this._camerasToBeAttached = this._cameras.slice();\n    // Initialize\n    this._scene = scene;\n    this._basePostProcess = originalPostProcess;\n    this._ratio = ratio;\n    // Misc\n    this._floatTextureType = scene.getEngine().getCaps().textureFloatRender ? 1 : 2;\n    // Finish\n    scene.postProcessRenderPipelineManager.addPipeline(this);\n    this._buildPipeline();\n  }\n  _buildPipeline() {\n    const ratio = this._ratio;\n    const scene = this._scene;\n    this._disposePostProcesses();\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);\n      // get back cameras to be used to reattach pipeline\n      this._cameras = this._camerasToBeAttached.slice();\n    }\n    this._reset();\n    // Create pass post-process\n    if (this._screenSpaceReflectionsEnabled) {\n      this.screenSpaceReflectionPostProcess = new ScreenSpaceReflectionPostProcess(\"HDRPass\", scene, ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, this._floatTextureType);\n      this.screenSpaceReflectionPostProcess.onApplyObservable.add(() => {\n        this._currentDepthOfFieldSource = this.screenSpaceReflectionPostProcess;\n      });\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRScreenSpaceReflections\", () => this.screenSpaceReflectionPostProcess, true));\n    }\n    if (!this._basePostProcess) {\n      this.originalPostProcess = new PostProcess(\"HDRPass\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", this._floatTextureType);\n    } else {\n      this.originalPostProcess = this._basePostProcess;\n    }\n    this.originalPostProcess.autoClear = !this.screenSpaceReflectionPostProcess;\n    this.originalPostProcess.onApplyObservable.add(() => {\n      this._currentDepthOfFieldSource = this.originalPostProcess;\n    });\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRPassPostProcess\", () => this.originalPostProcess, true));\n    if (this._bloomEnabled) {\n      // Create down sample X4 post-process\n      this._createDownSampleX4PostProcess(scene, ratio / 4);\n      // Create bright pass post-process\n      this._createBrightPassPostProcess(scene, ratio / 4);\n      // Create gaussian blur post-processes (down sampling blurs)\n      this._createBlurPostProcesses(scene, ratio / 4, 1);\n      // Create texture adder post-process\n      this._createTextureAdderPostProcess(scene, ratio);\n      // Create depth-of-field source post-process\n      this.textureAdderFinalPostProcess = new PostProcess(\"HDRDepthOfFieldSource\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRBaseDepthOfFieldSource\", () => {\n        return this.textureAdderFinalPostProcess;\n      }, true));\n    }\n    if (this._vlsEnabled) {\n      // Create volumetric light\n      this._createVolumetricLightPostProcess(scene, ratio);\n      // Create volumetric light final post-process\n      this.volumetricLightFinalPostProcess = new PostProcess(\"HDRVLSFinal\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRVLSFinal\", () => {\n        return this.volumetricLightFinalPostProcess;\n      }, true));\n    }\n    if (this._lensFlareEnabled) {\n      // Create lens flare post-process\n      this._createLensFlarePostProcess(scene, ratio);\n      // Create depth-of-field source post-process post lens-flare and disable it now\n      this.lensFlareFinalPostProcess = new PostProcess(\"HDRPostLensFlareDepthOfFieldSource\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRPostLensFlareDepthOfFieldSource\", () => {\n        return this.lensFlareFinalPostProcess;\n      }, true));\n    }\n    if (this._hdrEnabled) {\n      // Create luminance\n      this._createLuminancePostProcesses(scene, this._floatTextureType);\n      // Create HDR\n      this._createHdrPostProcess(scene, ratio);\n      // Create depth-of-field source post-process post hdr and disable it now\n      this.hdrFinalPostProcess = new PostProcess(\"HDRPostHDReDepthOfFieldSource\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRPostHDReDepthOfFieldSource\", () => {\n        return this.hdrFinalPostProcess;\n      }, true));\n    }\n    if (this._depthOfFieldEnabled) {\n      // Create gaussian blur used by depth-of-field\n      this._createBlurPostProcesses(scene, ratio / 2, 3, \"depthOfFieldBlurWidth\");\n      // Create depth-of-field post-process\n      this._createDepthOfFieldPostProcess(scene, ratio);\n    }\n    if (this._motionBlurEnabled) {\n      // Create motion blur post-process\n      this._createMotionBlurPostProcess(scene, ratio);\n    }\n    if (this._fxaaEnabled) {\n      // Create fxaa post-process\n      this.fxaaPostProcess = new FxaaPostProcess(\"fxaa\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRFxaa\", () => {\n        return this.fxaaPostProcess;\n      }, true));\n    }\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.attachCamerasToRenderPipeline(this._name, this._cameras);\n    }\n    if (!this._enableMSAAOnFirstPostProcess(this._samples) && this._samples > 1) {\n      Logger.Warn(\"MSAA failed to enable, MSAA is only supported in browsers that support webGL >= 2.0\");\n    }\n  }\n  // Down Sample X4 Post-Process\n  _createDownSampleX4PostProcess(scene, ratio) {\n    const downSampleX4Offsets = new Array(32);\n    this.downSampleX4PostProcess = new PostProcess(\"HDRDownSampleX4\", \"standard\", [\"dsOffsets\"], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define DOWN_SAMPLE_X4\", this._floatTextureType);\n    this.downSampleX4PostProcess.onApply = effect => {\n      let id = 0;\n      const width = this.downSampleX4PostProcess.width;\n      const height = this.downSampleX4PostProcess.height;\n      for (let i = -2; i < 2; i++) {\n        for (let j = -2; j < 2; j++) {\n          downSampleX4Offsets[id] = (i + 0.5) * (1.0 / width);\n          downSampleX4Offsets[id + 1] = (j + 0.5) * (1.0 / height);\n          id += 2;\n        }\n      }\n      effect.setArray2(\"dsOffsets\", downSampleX4Offsets);\n    };\n    // Add to pipeline\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRDownSampleX4\", () => {\n      return this.downSampleX4PostProcess;\n    }, true));\n  }\n  // Brightpass Post-Process\n  _createBrightPassPostProcess(scene, ratio) {\n    const brightOffsets = new Array(8);\n    this.brightPassPostProcess = new PostProcess(\"HDRBrightPass\", \"standard\", [\"dsOffsets\", \"brightThreshold\"], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define BRIGHT_PASS\", this._floatTextureType);\n    this.brightPassPostProcess.onApply = effect => {\n      const sU = 1.0 / this.brightPassPostProcess.width;\n      const sV = 1.0 / this.brightPassPostProcess.height;\n      brightOffsets[0] = -0.5 * sU;\n      brightOffsets[1] = 0.5 * sV;\n      brightOffsets[2] = 0.5 * sU;\n      brightOffsets[3] = 0.5 * sV;\n      brightOffsets[4] = -0.5 * sU;\n      brightOffsets[5] = -0.5 * sV;\n      brightOffsets[6] = 0.5 * sU;\n      brightOffsets[7] = -0.5 * sV;\n      effect.setArray2(\"dsOffsets\", brightOffsets);\n      effect.setFloat(\"brightThreshold\", this.brightThreshold);\n    };\n    // Add to pipeline\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRBrightPass\", () => {\n      return this.brightPassPostProcess;\n    }, true));\n  }\n  // Create blur H&V post-processes\n  _createBlurPostProcesses(scene, ratio, indice, blurWidthKey = \"blurWidth\") {\n    const engine = scene.getEngine();\n    const blurX = new BlurPostProcess(\"HDRBlurH\" + \"_\" + indice, new Vector2(1, 0), this[blurWidthKey], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, this._floatTextureType);\n    const blurY = new BlurPostProcess(\"HDRBlurV\" + \"_\" + indice, new Vector2(0, 1), this[blurWidthKey], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, this._floatTextureType);\n    blurX.onActivateObservable.add(() => {\n      const dw = blurX.width / engine.getRenderWidth();\n      blurX.kernel = this[blurWidthKey] * dw;\n    });\n    blurY.onActivateObservable.add(() => {\n      const dw = blurY.height / engine.getRenderHeight();\n      blurY.kernel = this.horizontalBlur ? 64 * dw : this[blurWidthKey] * dw;\n    });\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRBlurH\" + indice, () => {\n      return blurX;\n    }, true));\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRBlurV\" + indice, () => {\n      return blurY;\n    }, true));\n    this.blurHPostProcesses.push(blurX);\n    this.blurVPostProcesses.push(blurY);\n  }\n  // Create texture adder post-process\n  _createTextureAdderPostProcess(scene, ratio) {\n    this.textureAdderPostProcess = new PostProcess(\"HDRTextureAdder\", \"standard\", [\"exposure\"], [\"otherSampler\", \"lensSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define TEXTURE_ADDER\", this._floatTextureType);\n    this.textureAdderPostProcess.onApply = effect => {\n      effect.setTextureFromPostProcess(\"otherSampler\", this._vlsEnabled ? this._currentDepthOfFieldSource : this.originalPostProcess);\n      effect.setTexture(\"lensSampler\", this.lensTexture);\n      effect.setFloat(\"exposure\", this._currentExposure);\n      this._currentDepthOfFieldSource = this.textureAdderFinalPostProcess;\n    };\n    // Add to pipeline\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRTextureAdder\", () => {\n      return this.textureAdderPostProcess;\n    }, true));\n  }\n  _createVolumetricLightPostProcess(scene, ratio) {\n    const geometryRenderer = scene.enableGeometryBufferRenderer();\n    geometryRenderer.enablePosition = true;\n    const geometry = geometryRenderer.getGBuffer();\n    // Base post-process\n    this.volumetricLightPostProcess = new PostProcess(\"HDRVLS\", \"standard\", [\"shadowViewProjection\", \"cameraPosition\", \"sunDirection\", \"sunColor\", \"scatteringCoefficient\", \"scatteringPower\", \"depthValues\"], [\"shadowMapSampler\", \"positionSampler\"], ratio / 8, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define VLS\\n#define NB_STEPS \" + this._volumetricLightStepsCount.toFixed(1));\n    const depthValues = Vector2.Zero();\n    this.volumetricLightPostProcess.onApply = effect => {\n      if (this.sourceLight && this.sourceLight.getShadowGenerator() && this._scene.activeCamera) {\n        const generator = this.sourceLight.getShadowGenerator();\n        effect.setTexture(\"shadowMapSampler\", generator.getShadowMap());\n        effect.setTexture(\"positionSampler\", geometry.textures[2]);\n        effect.setColor3(\"sunColor\", this.sourceLight.diffuse);\n        effect.setVector3(\"sunDirection\", this.sourceLight.getShadowDirection());\n        effect.setVector3(\"cameraPosition\", this._scene.activeCamera.globalPosition);\n        effect.setMatrix(\"shadowViewProjection\", generator.getTransformMatrix());\n        effect.setFloat(\"scatteringCoefficient\", this.volumetricLightCoefficient);\n        effect.setFloat(\"scatteringPower\", this.volumetricLightPower);\n        depthValues.x = this.sourceLight.getDepthMinZ(this._scene.activeCamera);\n        depthValues.y = this.sourceLight.getDepthMaxZ(this._scene.activeCamera);\n        effect.setVector2(\"depthValues\", depthValues);\n      }\n    };\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRVLS\", () => {\n      return this.volumetricLightPostProcess;\n    }, true));\n    // Smooth\n    this._createBlurPostProcesses(scene, ratio / 4, 0, \"volumetricLightBlurScale\");\n    // Merge\n    this.volumetricLightMergePostProces = new PostProcess(\"HDRVLSMerge\", \"standard\", [], [\"originalSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define VLSMERGE\");\n    this.volumetricLightMergePostProces.onApply = effect => {\n      effect.setTextureFromPostProcess(\"originalSampler\", this._bloomEnabled ? this.textureAdderFinalPostProcess : this.originalPostProcess);\n      this._currentDepthOfFieldSource = this.volumetricLightFinalPostProcess;\n    };\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRVLSMerge\", () => {\n      return this.volumetricLightMergePostProces;\n    }, true));\n  }\n  // Create luminance\n  _createLuminancePostProcesses(scene, textureType) {\n    // Create luminance\n    let size = Math.pow(3, StandardRenderingPipeline.LuminanceSteps);\n    this.luminancePostProcess = new PostProcess(\"HDRLuminance\", \"standard\", [\"lumOffsets\"], [], {\n      width: size,\n      height: size\n    }, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define LUMINANCE\", textureType);\n    const offsets = [];\n    this.luminancePostProcess.onApply = effect => {\n      const sU = 1.0 / this.luminancePostProcess.width;\n      const sV = 1.0 / this.luminancePostProcess.height;\n      offsets[0] = -0.5 * sU;\n      offsets[1] = 0.5 * sV;\n      offsets[2] = 0.5 * sU;\n      offsets[3] = 0.5 * sV;\n      offsets[4] = -0.5 * sU;\n      offsets[5] = -0.5 * sV;\n      offsets[6] = 0.5 * sU;\n      offsets[7] = -0.5 * sV;\n      effect.setArray2(\"lumOffsets\", offsets);\n    };\n    // Add to pipeline\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRLuminance\", () => {\n      return this.luminancePostProcess;\n    }, true));\n    // Create down sample luminance\n    for (let i = StandardRenderingPipeline.LuminanceSteps - 1; i >= 0; i--) {\n      size = Math.pow(3, i);\n      let defines = \"#define LUMINANCE_DOWN_SAMPLE\\n\";\n      if (i === 0) {\n        defines += \"#define FINAL_DOWN_SAMPLER\";\n      }\n      const postProcess = new PostProcess(\"HDRLuminanceDownSample\" + i, \"standard\", [\"dsOffsets\", \"halfDestPixelSize\"], [], {\n        width: size,\n        height: size\n      }, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, defines, textureType);\n      this.luminanceDownSamplePostProcesses.push(postProcess);\n    }\n    // Create callbacks and add effects\n    let lastLuminance = this.luminancePostProcess;\n    this.luminanceDownSamplePostProcesses.forEach((pp, index) => {\n      const downSampleOffsets = new Array(18);\n      pp.onApply = effect => {\n        if (!lastLuminance) {\n          return;\n        }\n        let id = 0;\n        for (let x = -1; x < 2; x++) {\n          for (let y = -1; y < 2; y++) {\n            downSampleOffsets[id] = x / lastLuminance.width;\n            downSampleOffsets[id + 1] = y / lastLuminance.height;\n            id += 2;\n          }\n        }\n        effect.setArray2(\"dsOffsets\", downSampleOffsets);\n        effect.setFloat(\"halfDestPixelSize\", 0.5 / lastLuminance.width);\n        if (index === this.luminanceDownSamplePostProcesses.length - 1) {\n          lastLuminance = this.luminancePostProcess;\n        } else {\n          lastLuminance = pp;\n        }\n      };\n      if (index === this.luminanceDownSamplePostProcesses.length - 1) {\n        pp.onAfterRender = () => {\n          const pixel = scene.getEngine().readPixels(0, 0, 1, 1);\n          const bit_shift = new Vector4(1.0 / (255.0 * 255.0 * 255.0), 1.0 / (255.0 * 255.0), 1.0 / 255.0, 1.0);\n          pixel.then(pixel => {\n            const data = new Uint8Array(pixel.buffer);\n            this._hdrCurrentLuminance = (data[0] * bit_shift.x + data[1] * bit_shift.y + data[2] * bit_shift.z + data[3] * bit_shift.w) / 100.0;\n          });\n        };\n      }\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRLuminanceDownSample\" + index, () => {\n        return pp;\n      }, true));\n    });\n  }\n  // Create HDR post-process\n  _createHdrPostProcess(scene, ratio) {\n    const defines = [\"#define HDR\"];\n    if (this._hdrAutoExposure) {\n      defines.push(\"#define AUTO_EXPOSURE\");\n    }\n    this.hdrPostProcess = new PostProcess(\"HDR\", \"standard\", [\"averageLuminance\"], [\"textureAdderSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, defines.join(\"\\n\"), 0);\n    let outputLiminance = 1;\n    let time = 0;\n    let lastTime = 0;\n    this.hdrPostProcess.onApply = effect => {\n      effect.setTextureFromPostProcess(\"textureAdderSampler\", this._currentDepthOfFieldSource);\n      time += scene.getEngine().getDeltaTime();\n      if (outputLiminance < 0) {\n        outputLiminance = this._hdrCurrentLuminance;\n      } else {\n        const dt = (lastTime - time) / 1000.0;\n        if (this._hdrCurrentLuminance < outputLiminance + this.hdrDecreaseRate * dt) {\n          outputLiminance += this.hdrDecreaseRate * dt;\n        } else if (this._hdrCurrentLuminance > outputLiminance - this.hdrIncreaseRate * dt) {\n          outputLiminance -= this.hdrIncreaseRate * dt;\n        } else {\n          outputLiminance = this._hdrCurrentLuminance;\n        }\n      }\n      if (this.hdrAutoExposure) {\n        this._currentExposure = this._fixedExposure / outputLiminance;\n      } else {\n        outputLiminance = Scalar.Clamp(outputLiminance, this.hdrMinimumLuminance, 1e20);\n        effect.setFloat(\"averageLuminance\", outputLiminance);\n      }\n      lastTime = time;\n      this._currentDepthOfFieldSource = this.hdrFinalPostProcess;\n    };\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDR\", () => {\n      return this.hdrPostProcess;\n    }, true));\n  }\n  // Create lens flare post-process\n  _createLensFlarePostProcess(scene, ratio) {\n    this.lensFlarePostProcess = new PostProcess(\"HDRLensFlare\", \"standard\", [\"strength\", \"ghostDispersal\", \"haloWidth\", \"resolution\", \"distortionStrength\"], [\"lensColorSampler\"], ratio / 2, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define LENS_FLARE\", 0);\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRLensFlare\", () => {\n      return this.lensFlarePostProcess;\n    }, true));\n    this._createBlurPostProcesses(scene, ratio / 4, 2, \"lensFlareBlurWidth\");\n    this.lensFlareComposePostProcess = new PostProcess(\"HDRLensFlareCompose\", \"standard\", [\"lensStarMatrix\"], [\"otherSampler\", \"lensDirtSampler\", \"lensStarSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define LENS_FLARE_COMPOSE\", 0);\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRLensFlareCompose\", () => {\n      return this.lensFlareComposePostProcess;\n    }, true));\n    const resolution = new Vector2(0, 0);\n    // Lens flare\n    this.lensFlarePostProcess.externalTextureSamplerBinding = true;\n    this.lensFlarePostProcess.onApply = effect => {\n      effect.setTextureFromPostProcess(\"textureSampler\", this._bloomEnabled ? this.blurHPostProcesses[0] : this.originalPostProcess);\n      effect.setTexture(\"lensColorSampler\", this.lensColorTexture);\n      effect.setFloat(\"strength\", this.lensFlareStrength);\n      effect.setFloat(\"ghostDispersal\", this.lensFlareGhostDispersal);\n      effect.setFloat(\"haloWidth\", this.lensFlareHaloWidth);\n      // Shift\n      resolution.x = this.lensFlarePostProcess.width;\n      resolution.y = this.lensFlarePostProcess.height;\n      effect.setVector2(\"resolution\", resolution);\n      effect.setFloat(\"distortionStrength\", this.lensFlareDistortionStrength);\n    };\n    // Compose\n    const scaleBias1 = Matrix.FromValues(2.0, 0.0, -1.0, 0.0, 0.0, 2.0, -1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0);\n    const scaleBias2 = Matrix.FromValues(0.5, 0.0, 0.5, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0);\n    this.lensFlareComposePostProcess.onApply = effect => {\n      if (!this._scene.activeCamera) {\n        return;\n      }\n      effect.setTextureFromPostProcess(\"otherSampler\", this.lensFlarePostProcess);\n      effect.setTexture(\"lensDirtSampler\", this.lensFlareDirtTexture);\n      effect.setTexture(\"lensStarSampler\", this.lensStarTexture);\n      // Lens start rotation matrix\n      const camerax = this._scene.activeCamera.getViewMatrix().getRow(0);\n      const cameraz = this._scene.activeCamera.getViewMatrix().getRow(2);\n      let camRot = Vector3.Dot(camerax.toVector3(), new Vector3(1.0, 0.0, 0.0)) + Vector3.Dot(cameraz.toVector3(), new Vector3(0.0, 0.0, 1.0));\n      camRot *= 4.0;\n      const starRotation = Matrix.FromValues(Math.cos(camRot) * 0.5, -Math.sin(camRot), 0.0, 0.0, Math.sin(camRot), Math.cos(camRot) * 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0);\n      const lensStarMatrix = scaleBias2.multiply(starRotation).multiply(scaleBias1);\n      effect.setMatrix(\"lensStarMatrix\", lensStarMatrix);\n      this._currentDepthOfFieldSource = this.lensFlareFinalPostProcess;\n    };\n  }\n  // Create depth-of-field post-process\n  _createDepthOfFieldPostProcess(scene, ratio) {\n    this.depthOfFieldPostProcess = new PostProcess(\"HDRDepthOfField\", \"standard\", [\"distance\"], [\"otherSampler\", \"depthSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define DEPTH_OF_FIELD\", 0);\n    this.depthOfFieldPostProcess.onApply = effect => {\n      effect.setTextureFromPostProcess(\"otherSampler\", this._currentDepthOfFieldSource);\n      effect.setTexture(\"depthSampler\", this._getDepthTexture());\n      effect.setFloat(\"distance\", this.depthOfFieldDistance);\n    };\n    // Add to pipeline\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRDepthOfField\", () => {\n      return this.depthOfFieldPostProcess;\n    }, true));\n  }\n  // Create motion blur post-process\n  _createMotionBlurPostProcess(scene, ratio) {\n    if (this._isObjectBasedMotionBlur) {\n      const mb = new MotionBlurPostProcess(\"HDRMotionBlur\", scene, ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, 0);\n      mb.motionStrength = this.motionStrength;\n      mb.motionBlurSamples = this.motionBlurSamples;\n      this.motionBlurPostProcess = mb;\n    } else {\n      this.motionBlurPostProcess = new PostProcess(\"HDRMotionBlur\", \"standard\", [\"inverseViewProjection\", \"prevViewProjection\", \"screenSize\", \"motionScale\", \"motionStrength\"], [\"depthSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define MOTION_BLUR\\n#define MAX_MOTION_SAMPLES \" + this.motionBlurSamples.toFixed(1), 0);\n      let motionScale = 0;\n      let prevViewProjection = Matrix.Identity();\n      const invViewProjection = Matrix.Identity();\n      let viewProjection = Matrix.Identity();\n      const screenSize = Vector2.Zero();\n      this.motionBlurPostProcess.onApply = effect => {\n        viewProjection = scene.getProjectionMatrix().multiply(scene.getViewMatrix());\n        viewProjection.invertToRef(invViewProjection);\n        effect.setMatrix(\"inverseViewProjection\", invViewProjection);\n        effect.setMatrix(\"prevViewProjection\", prevViewProjection);\n        prevViewProjection = viewProjection;\n        screenSize.x = this.motionBlurPostProcess.width;\n        screenSize.y = this.motionBlurPostProcess.height;\n        effect.setVector2(\"screenSize\", screenSize);\n        motionScale = scene.getEngine().getFps() / 60.0;\n        effect.setFloat(\"motionScale\", motionScale);\n        effect.setFloat(\"motionStrength\", this.motionStrength);\n        effect.setTexture(\"depthSampler\", this._getDepthTexture());\n      };\n    }\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRMotionBlur\", () => {\n      return this.motionBlurPostProcess;\n    }, true));\n  }\n  _getDepthTexture() {\n    if (this._scene.getEngine().getCaps().drawBuffersExtension) {\n      const renderer = this._scene.enableGeometryBufferRenderer();\n      return renderer.getGBuffer().textures[0];\n    }\n    return this._scene.enableDepthRenderer().getDepthMap();\n  }\n  _disposePostProcesses() {\n    for (let i = 0; i < this._cameras.length; i++) {\n      const camera = this._cameras[i];\n      if (this.originalPostProcess) {\n        this.originalPostProcess.dispose(camera);\n      }\n      if (this.screenSpaceReflectionPostProcess) {\n        this.screenSpaceReflectionPostProcess.dispose(camera);\n      }\n      if (this.downSampleX4PostProcess) {\n        this.downSampleX4PostProcess.dispose(camera);\n      }\n      if (this.brightPassPostProcess) {\n        this.brightPassPostProcess.dispose(camera);\n      }\n      if (this.textureAdderPostProcess) {\n        this.textureAdderPostProcess.dispose(camera);\n      }\n      if (this.volumetricLightPostProcess) {\n        this.volumetricLightPostProcess.dispose(camera);\n      }\n      if (this.volumetricLightSmoothXPostProcess) {\n        this.volumetricLightSmoothXPostProcess.dispose(camera);\n      }\n      if (this.volumetricLightSmoothYPostProcess) {\n        this.volumetricLightSmoothYPostProcess.dispose(camera);\n      }\n      if (this.volumetricLightMergePostProces) {\n        this.volumetricLightMergePostProces.dispose(camera);\n      }\n      if (this.volumetricLightFinalPostProcess) {\n        this.volumetricLightFinalPostProcess.dispose(camera);\n      }\n      if (this.lensFlarePostProcess) {\n        this.lensFlarePostProcess.dispose(camera);\n      }\n      if (this.lensFlareComposePostProcess) {\n        this.lensFlareComposePostProcess.dispose(camera);\n      }\n      for (let j = 0; j < this.luminanceDownSamplePostProcesses.length; j++) {\n        this.luminanceDownSamplePostProcesses[j].dispose(camera);\n      }\n      if (this.luminancePostProcess) {\n        this.luminancePostProcess.dispose(camera);\n      }\n      if (this.hdrPostProcess) {\n        this.hdrPostProcess.dispose(camera);\n      }\n      if (this.hdrFinalPostProcess) {\n        this.hdrFinalPostProcess.dispose(camera);\n      }\n      if (this.depthOfFieldPostProcess) {\n        this.depthOfFieldPostProcess.dispose(camera);\n      }\n      if (this.motionBlurPostProcess) {\n        this.motionBlurPostProcess.dispose(camera);\n      }\n      if (this.fxaaPostProcess) {\n        this.fxaaPostProcess.dispose(camera);\n      }\n      for (let j = 0; j < this.blurHPostProcesses.length; j++) {\n        this.blurHPostProcesses[j].dispose(camera);\n      }\n      for (let j = 0; j < this.blurVPostProcesses.length; j++) {\n        this.blurVPostProcesses[j].dispose(camera);\n      }\n    }\n    this.originalPostProcess = null;\n    this.downSampleX4PostProcess = null;\n    this.brightPassPostProcess = null;\n    this.textureAdderPostProcess = null;\n    this.textureAdderFinalPostProcess = null;\n    this.volumetricLightPostProcess = null;\n    this.volumetricLightSmoothXPostProcess = null;\n    this.volumetricLightSmoothYPostProcess = null;\n    this.volumetricLightMergePostProces = null;\n    this.volumetricLightFinalPostProcess = null;\n    this.lensFlarePostProcess = null;\n    this.lensFlareComposePostProcess = null;\n    this.luminancePostProcess = null;\n    this.hdrPostProcess = null;\n    this.hdrFinalPostProcess = null;\n    this.depthOfFieldPostProcess = null;\n    this.motionBlurPostProcess = null;\n    this.fxaaPostProcess = null;\n    this.screenSpaceReflectionPostProcess = null;\n    this.luminanceDownSamplePostProcesses.length = 0;\n    this.blurHPostProcesses.length = 0;\n    this.blurVPostProcesses.length = 0;\n  }\n  /**\n   * Dispose of the pipeline and stop all post processes\n   */\n  dispose() {\n    this._disposePostProcesses();\n    this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);\n    super.dispose();\n  }\n  /**\n   * Serialize the rendering pipeline (Used when exporting)\n   * @returns the serialized object\n   */\n  serialize() {\n    const serializationObject = SerializationHelper.Serialize(this);\n    if (this.sourceLight) {\n      serializationObject.sourceLightId = this.sourceLight.id;\n    }\n    if (this.screenSpaceReflectionPostProcess) {\n      serializationObject.screenSpaceReflectionPostProcess = SerializationHelper.Serialize(this.screenSpaceReflectionPostProcess);\n    }\n    serializationObject.customType = \"StandardRenderingPipeline\";\n    return serializationObject;\n  }\n  /**\n   * Parse the serialized pipeline\n   * @param source Source pipeline.\n   * @param scene The scene to load the pipeline to.\n   * @param rootUrl The URL of the serialized pipeline.\n   * @returns An instantiated pipeline from the serialized object.\n   */\n  static Parse(source, scene, rootUrl) {\n    const p = SerializationHelper.Parse(() => new StandardRenderingPipeline(source._name, scene, source._ratio), source, scene, rootUrl);\n    if (source.sourceLightId) {\n      p.sourceLight = scene.getLightById(source.sourceLightId);\n    }\n    if (source.screenSpaceReflectionPostProcess) {\n      SerializationHelper.Parse(() => p.screenSpaceReflectionPostProcess, source.screenSpaceReflectionPostProcess, scene, rootUrl);\n    }\n    return p;\n  }\n}\n/**\n * Luminance steps\n */\nStandardRenderingPipeline.LuminanceSteps = 6;\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"brightThreshold\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"blurWidth\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"horizontalBlur\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"exposure\", null);\n__decorate([serializeAsTexture(\"lensTexture\")], StandardRenderingPipeline.prototype, \"lensTexture\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"volumetricLightCoefficient\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"volumetricLightPower\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"volumetricLightBlurScale\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"hdrMinimumLuminance\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"hdrDecreaseRate\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"hdrIncreaseRate\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"hdrAutoExposure\", null);\n__decorate([serializeAsTexture(\"lensColorTexture\")], StandardRenderingPipeline.prototype, \"lensColorTexture\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareStrength\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareGhostDispersal\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareHaloWidth\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareDistortionStrength\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareBlurWidth\", void 0);\n__decorate([serializeAsTexture(\"lensStarTexture\")], StandardRenderingPipeline.prototype, \"lensStarTexture\", void 0);\n__decorate([serializeAsTexture(\"lensFlareDirtTexture\")], StandardRenderingPipeline.prototype, \"lensFlareDirtTexture\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"depthOfFieldDistance\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"depthOfFieldBlurWidth\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"motionStrength\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"objectBasedMotionBlur\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"_ratio\", void 0);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"BloomEnabled\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"DepthOfFieldEnabled\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"LensFlareEnabled\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"HDREnabled\", null);\n__decorate([serialize()\n// eslint-disable-next-line @typescript-eslint/naming-convention\n], StandardRenderingPipeline.prototype, \"VLSEnabled\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"MotionBlurEnabled\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"fxaaEnabled\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"screenSpaceReflectionsEnabled\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"volumetricLightStepsCount\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"motionBlurSamples\", null);\n__decorate([serialize()], StandardRenderingPipeline.prototype, \"samples\", null);\nRegisterClass(\"BABYLON.StandardRenderingPipeline\", StandardRenderingPipeline);\n//# sourceMappingURL=standardRenderingPipeline.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}