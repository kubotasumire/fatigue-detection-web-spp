{"ast":null,"code":"import { Tools } from \"../Misc/tools.js\";\nimport { Observable } from \"../Misc/observable.js\";\nimport { Vector3 } from \"../Maths/math.vector.js\";\nimport { Engine } from \"../Engines/engine.js\";\nimport { Logger } from \"../Misc/logger.js\";\nimport { _WarnImport } from \"../Misc/devTools.js\";\nimport { EngineStore } from \"../Engines/engineStore.js\";\n/**\n * Defines a sound that can be played in the application.\n * The sound can either be an ambient track or a simple sound played in reaction to a user action.\n * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic\n */\nexport class Sound {\n  /**\n   * Does the sound loop after it finishes playing once.\n   */\n  get loop() {\n    return this._loop;\n  }\n  set loop(value) {\n    if (value === this._loop) {\n      return;\n    }\n    this._loop = value;\n    this.updateOptions({\n      loop: value\n    });\n  }\n  /**\n   * Gets the current time for the sound.\n   */\n  get currentTime() {\n    if (this._htmlAudioElement) {\n      return this._htmlAudioElement.currentTime;\n    }\n    if (Engine.audioEngine?.audioContext && (this.isPlaying || this.isPaused)) {\n      // The `_currentTime` member is only updated when the sound is paused. Add the time since the last start\n      // to get the actual current time.\n      const timeSinceLastStart = this.isPaused ? 0 : Engine.audioEngine.audioContext.currentTime - this._startTime;\n      return this._currentTime + timeSinceLastStart;\n    }\n    return 0;\n  }\n  /**\n   * Does this sound enables spatial sound.\n   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound\n   */\n  get spatialSound() {\n    return this._spatialSound;\n  }\n  /**\n   * Does this sound enables spatial sound.\n   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound\n   */\n  set spatialSound(newValue) {\n    if (newValue == this._spatialSound) {\n      return;\n    }\n    const wasPlaying = this.isPlaying;\n    this.pause();\n    if (newValue) {\n      this._spatialSound = newValue;\n      this._updateSpatialParameters();\n    } else {\n      this._disableSpatialSound();\n    }\n    if (wasPlaying) {\n      this.play();\n    }\n  }\n  /**\n   * Create a sound and attach it to a scene\n   * @param name Name of your sound\n   * @param urlOrArrayBuffer Url to the sound to load async or ArrayBuffer, it also works with MediaStreams and AudioBuffers\n   * @param scene defines the scene the sound belongs to\n   * @param readyToPlayCallback Provide a callback function if you'd like to load your code once the sound is ready to be played\n   * @param options Objects to provide with the current available options: autoplay, loop, volume, spatialSound, maxDistance, rolloffFactor, refDistance, distanceModel, panningModel, streaming\n   */\n  constructor(name, urlOrArrayBuffer, scene, readyToPlayCallback = null, options) {\n    /**\n     * Does the sound autoplay once loaded.\n     */\n    this.autoplay = false;\n    this._loop = false;\n    /**\n     * Does the sound use a custom attenuation curve to simulate the falloff\n     * happening when the source gets further away from the camera.\n     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-your-own-custom-attenuation-function\n     */\n    this.useCustomAttenuation = false;\n    /**\n     * Is this sound currently played.\n     */\n    this.isPlaying = false;\n    /**\n     * Is this sound currently paused.\n     */\n    this.isPaused = false;\n    /**\n     * Define the reference distance the sound should be heard perfectly.\n     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound\n     */\n    this.refDistance = 1;\n    /**\n     * Define the roll off factor of spatial sounds.\n     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound\n     */\n    this.rolloffFactor = 1;\n    /**\n     * Define the max distance the sound should be heard (intensity just became 0 at this point).\n     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound\n     */\n    this.maxDistance = 100;\n    /**\n     * Define the distance attenuation model the sound will follow.\n     * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound\n     */\n    this.distanceModel = \"linear\";\n    /**\n     * Gets or sets an object used to store user defined information for the sound.\n     */\n    this.metadata = null;\n    /**\n     * Observable event when the current playing sound finishes.\n     */\n    this.onEndedObservable = new Observable();\n    this._spatialSound = false;\n    this._panningModel = \"equalpower\";\n    this._playbackRate = 1;\n    this._streaming = false;\n    this._startTime = 0;\n    this._currentTime = 0;\n    this._position = Vector3.Zero();\n    this._localDirection = new Vector3(1, 0, 0);\n    this._volume = 1;\n    this._isReadyToPlay = false;\n    this._isDirectional = false;\n    // Used if you'd like to create a directional sound.\n    // If not set, the sound will be omnidirectional\n    this._coneInnerAngle = 360;\n    this._coneOuterAngle = 360;\n    this._coneOuterGain = 0;\n    this._isOutputConnected = false;\n    this._urlType = \"Unknown\";\n    this.name = name;\n    scene = scene || EngineStore.LastCreatedScene;\n    if (!scene) {\n      return;\n    }\n    this._scene = scene;\n    Sound._SceneComponentInitialization(scene);\n    this._readyToPlayCallback = readyToPlayCallback;\n    // Default custom attenuation function is a linear attenuation\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    this._customAttenuationFunction = (currentVolume, currentDistance, maxDistance, refDistance, rolloffFactor) => {\n      if (currentDistance < maxDistance) {\n        return currentVolume * (1 - currentDistance / maxDistance);\n      } else {\n        return 0;\n      }\n    };\n    if (options) {\n      this.autoplay = options.autoplay || false;\n      this._loop = options.loop || false;\n      // if volume === 0, we need another way to check this option\n      if (options.volume !== undefined) {\n        this._volume = options.volume;\n      }\n      this._spatialSound = options.spatialSound ?? false;\n      this.maxDistance = options.maxDistance ?? 100;\n      this.useCustomAttenuation = options.useCustomAttenuation ?? false;\n      this.rolloffFactor = options.rolloffFactor || 1;\n      this.refDistance = options.refDistance || 1;\n      this.distanceModel = options.distanceModel || \"linear\";\n      this._playbackRate = options.playbackRate || 1;\n      this._streaming = options.streaming ?? false;\n      this._length = options.length;\n      this._offset = options.offset;\n    }\n    if (Engine.audioEngine?.canUseWebAudio && Engine.audioEngine.audioContext) {\n      this._soundGain = Engine.audioEngine.audioContext.createGain();\n      this._soundGain.gain.value = this._volume;\n      this._inputAudioNode = this._soundGain;\n      this._outputAudioNode = this._soundGain;\n      if (this._spatialSound) {\n        this._createSpatialParameters();\n      }\n      this._scene.mainSoundTrack.addSound(this);\n      let validParameter = true;\n      // if no parameter is passed, you need to call setAudioBuffer yourself to prepare the sound\n      if (urlOrArrayBuffer) {\n        try {\n          if (typeof urlOrArrayBuffer === \"string\") {\n            this._urlType = \"String\";\n            this._url = urlOrArrayBuffer;\n          } else if (urlOrArrayBuffer instanceof ArrayBuffer) {\n            this._urlType = \"ArrayBuffer\";\n          } else if (urlOrArrayBuffer instanceof HTMLMediaElement) {\n            this._urlType = \"MediaElement\";\n          } else if (urlOrArrayBuffer instanceof MediaStream) {\n            this._urlType = \"MediaStream\";\n          } else if (urlOrArrayBuffer instanceof AudioBuffer) {\n            this._urlType = \"AudioBuffer\";\n          } else if (Array.isArray(urlOrArrayBuffer)) {\n            this._urlType = \"Array\";\n          }\n          let urls = [];\n          let codecSupportedFound = false;\n          switch (this._urlType) {\n            case \"MediaElement\":\n              this._streaming = true;\n              this._isReadyToPlay = true;\n              this._streamingSource = Engine.audioEngine.audioContext.createMediaElementSource(urlOrArrayBuffer);\n              if (this.autoplay) {\n                this.play(0, this._offset, this._length);\n              }\n              if (this._readyToPlayCallback) {\n                this._readyToPlayCallback();\n              }\n              break;\n            case \"MediaStream\":\n              this._streaming = true;\n              this._isReadyToPlay = true;\n              this._streamingSource = Engine.audioEngine.audioContext.createMediaStreamSource(urlOrArrayBuffer);\n              if (this.autoplay) {\n                this.play(0, this._offset, this._length);\n              }\n              if (this._readyToPlayCallback) {\n                this._readyToPlayCallback();\n              }\n              break;\n            case \"ArrayBuffer\":\n              if (urlOrArrayBuffer.byteLength > 0) {\n                codecSupportedFound = true;\n                this._soundLoaded(urlOrArrayBuffer);\n              }\n              break;\n            case \"AudioBuffer\":\n              this._audioBufferLoaded(urlOrArrayBuffer);\n              break;\n            case \"String\":\n              urls.push(urlOrArrayBuffer);\n            // eslint-disable-next-line no-fallthrough\n            case \"Array\":\n              if (urls.length === 0) {\n                urls = urlOrArrayBuffer;\n              }\n              // If we found a supported format, we load it immediately and stop the loop\n              for (let i = 0; i < urls.length; i++) {\n                const url = urls[i];\n                codecSupportedFound = options && options.skipCodecCheck || url.indexOf(\".mp3\", url.length - 4) !== -1 && Engine.audioEngine.isMP3supported || url.indexOf(\".ogg\", url.length - 4) !== -1 && Engine.audioEngine.isOGGsupported || url.indexOf(\".wav\", url.length - 4) !== -1 || url.indexOf(\".m4a\", url.length - 4) !== -1 || url.indexOf(\".mp4\", url.length - 4) !== -1 || url.indexOf(\"blob:\") !== -1;\n                if (codecSupportedFound) {\n                  // Loading sound\n                  if (!this._streaming) {\n                    this._scene._loadFile(url, data => {\n                      this._soundLoaded(data);\n                    }, undefined, true, true, exception => {\n                      if (exception) {\n                        Logger.Error(\"XHR \" + exception.status + \" error on: \" + url + \".\");\n                      }\n                      Logger.Error(\"Sound creation aborted.\");\n                      this._scene.mainSoundTrack.removeSound(this);\n                    });\n                  }\n                  // Streaming sound using HTML5 Audio tag\n                  else {\n                    this._htmlAudioElement = new Audio(url);\n                    this._htmlAudioElement.controls = false;\n                    this._htmlAudioElement.loop = this.loop;\n                    Tools.SetCorsBehavior(url, this._htmlAudioElement);\n                    this._htmlAudioElement.preload = \"auto\";\n                    this._htmlAudioElement.addEventListener(\"canplaythrough\", () => {\n                      this._isReadyToPlay = true;\n                      if (this.autoplay) {\n                        this.play(0, this._offset, this._length);\n                      }\n                      if (this._readyToPlayCallback) {\n                        this._readyToPlayCallback();\n                      }\n                    });\n                    document.body.appendChild(this._htmlAudioElement);\n                    this._htmlAudioElement.load();\n                  }\n                  break;\n                }\n              }\n              break;\n            default:\n              validParameter = false;\n              break;\n          }\n          if (!validParameter) {\n            Logger.Error(\"Parameter must be a URL to the sound, an Array of URLs (.mp3 & .ogg) or an ArrayBuffer of the sound.\");\n          } else {\n            if (!codecSupportedFound) {\n              this._isReadyToPlay = true;\n              // Simulating a ready to play event to avoid breaking code path\n              if (this._readyToPlayCallback) {\n                setTimeout(() => {\n                  if (this._readyToPlayCallback) {\n                    this._readyToPlayCallback();\n                  }\n                }, 1000);\n              }\n            }\n          }\n        } catch (ex) {\n          Logger.Error(\"Unexpected error. Sound creation aborted.\");\n          this._scene.mainSoundTrack.removeSound(this);\n        }\n      }\n    } else {\n      // Adding an empty sound to avoid breaking audio calls for non Web Audio browsers\n      this._scene.mainSoundTrack.addSound(this);\n      if (Engine.audioEngine && !Engine.audioEngine.WarnedWebAudioUnsupported) {\n        Logger.Error(\"Web Audio is not supported by your browser.\");\n        Engine.audioEngine.WarnedWebAudioUnsupported = true;\n      }\n      // Simulating a ready to play event to avoid breaking code for non web audio browsers\n      if (this._readyToPlayCallback) {\n        setTimeout(() => {\n          if (this._readyToPlayCallback) {\n            this._readyToPlayCallback();\n          }\n        }, 1000);\n      }\n    }\n  }\n  /**\n   * Release the sound and its associated resources\n   */\n  dispose() {\n    if (Engine.audioEngine?.canUseWebAudio) {\n      if (this.isPlaying) {\n        this.stop();\n      }\n      this._isReadyToPlay = false;\n      if (this.soundTrackId === -1) {\n        this._scene.mainSoundTrack.removeSound(this);\n      } else if (this._scene.soundTracks) {\n        this._scene.soundTracks[this.soundTrackId].removeSound(this);\n      }\n      if (this._soundGain) {\n        this._soundGain.disconnect();\n        this._soundGain = null;\n      }\n      if (this._soundPanner) {\n        this._soundPanner.disconnect();\n        this._soundPanner = null;\n      }\n      if (this._soundSource) {\n        this._soundSource.disconnect();\n        this._soundSource = null;\n      }\n      this._audioBuffer = null;\n      if (this._htmlAudioElement) {\n        this._htmlAudioElement.pause();\n        this._htmlAudioElement.src = \"\";\n        document.body.removeChild(this._htmlAudioElement);\n      }\n      if (this._streamingSource) {\n        this._streamingSource.disconnect();\n      }\n      if (this._connectedTransformNode && this._registerFunc) {\n        this._connectedTransformNode.unregisterAfterWorldMatrixUpdate(this._registerFunc);\n        this._connectedTransformNode = null;\n      }\n      this._clearTimeoutsAndObservers();\n    }\n  }\n  /**\n   * Gets if the sounds is ready to be played or not.\n   * @returns true if ready, otherwise false\n   */\n  isReady() {\n    return this._isReadyToPlay;\n  }\n  /**\n   * Get the current class name.\n   * @returns current class name\n   */\n  getClassName() {\n    return \"Sound\";\n  }\n  _audioBufferLoaded(buffer) {\n    if (!Engine.audioEngine?.audioContext) {\n      return;\n    }\n    this._audioBuffer = buffer;\n    this._isReadyToPlay = true;\n    if (this.autoplay) {\n      this.play(0, this._offset, this._length);\n    }\n    if (this._readyToPlayCallback) {\n      this._readyToPlayCallback();\n    }\n  }\n  _soundLoaded(audioData) {\n    if (!Engine.audioEngine?.audioContext) {\n      return;\n    }\n    Engine.audioEngine.audioContext.decodeAudioData(audioData, buffer => {\n      this._audioBufferLoaded(buffer);\n    }, err => {\n      Logger.Error(\"Error while decoding audio data for: \" + this.name + \" / Error: \" + err);\n    });\n  }\n  /**\n   * Sets the data of the sound from an audiobuffer\n   * @param audioBuffer The audioBuffer containing the data\n   */\n  setAudioBuffer(audioBuffer) {\n    if (Engine.audioEngine?.canUseWebAudio) {\n      this._audioBuffer = audioBuffer;\n      this._isReadyToPlay = true;\n    }\n  }\n  /**\n   * Updates the current sounds options such as maxdistance, loop...\n   * @param options A JSON object containing values named as the object properties\n   */\n  updateOptions(options) {\n    if (options) {\n      this.loop = options.loop ?? this.loop;\n      this.maxDistance = options.maxDistance ?? this.maxDistance;\n      this.useCustomAttenuation = options.useCustomAttenuation ?? this.useCustomAttenuation;\n      this.rolloffFactor = options.rolloffFactor ?? this.rolloffFactor;\n      this.refDistance = options.refDistance ?? this.refDistance;\n      this.distanceModel = options.distanceModel ?? this.distanceModel;\n      this._playbackRate = options.playbackRate ?? this._playbackRate;\n      this._length = options.length ?? undefined;\n      this.spatialSound = options.spatialSound ?? this._spatialSound;\n      this._setOffset(options.offset ?? undefined);\n      this.setVolume(options.volume ?? this._volume);\n      this._updateSpatialParameters();\n      if (this.isPlaying) {\n        if (this._streaming && this._htmlAudioElement) {\n          this._htmlAudioElement.playbackRate = this._playbackRate;\n          if (this._htmlAudioElement.loop !== this.loop) {\n            this._htmlAudioElement.loop = this.loop;\n          }\n        } else {\n          if (this._soundSource) {\n            this._soundSource.playbackRate.value = this._playbackRate;\n            if (this._soundSource.loop !== this.loop) {\n              this._soundSource.loop = this.loop;\n            }\n            if (this._offset !== undefined && this._soundSource.loopStart !== this._offset) {\n              this._soundSource.loopStart = this._offset;\n            }\n            if (this._length !== undefined && this._length !== this._soundSource.loopEnd) {\n              this._soundSource.loopEnd = (this._offset | 0) + this._length;\n            }\n          }\n        }\n      }\n    }\n  }\n  _createSpatialParameters() {\n    if (Engine.audioEngine?.canUseWebAudio && Engine.audioEngine.audioContext) {\n      if (this._scene.headphone) {\n        this._panningModel = \"HRTF\";\n      }\n      this._soundPanner = this._soundPanner ?? Engine.audioEngine.audioContext.createPanner();\n      if (this._soundPanner && this._outputAudioNode) {\n        this._updateSpatialParameters();\n        this._soundPanner.connect(this._outputAudioNode);\n        this._inputAudioNode = this._soundPanner;\n      }\n    }\n  }\n  _disableSpatialSound() {\n    if (!this._spatialSound) {\n      return;\n    }\n    this._inputAudioNode = this._soundGain;\n    this._soundPanner?.disconnect();\n    this._soundPanner = null;\n    this._spatialSound = false;\n  }\n  _updateSpatialParameters() {\n    if (!this._spatialSound) {\n      return;\n    }\n    if (this._soundPanner) {\n      if (this.useCustomAttenuation) {\n        // Tricks to disable in a way embedded Web Audio attenuation\n        this._soundPanner.distanceModel = \"linear\";\n        this._soundPanner.maxDistance = Number.MAX_VALUE;\n        this._soundPanner.refDistance = 1;\n        this._soundPanner.rolloffFactor = 1;\n        this._soundPanner.panningModel = this._panningModel;\n      } else {\n        this._soundPanner.distanceModel = this.distanceModel;\n        this._soundPanner.maxDistance = this.maxDistance;\n        this._soundPanner.refDistance = this.refDistance;\n        this._soundPanner.rolloffFactor = this.rolloffFactor;\n        this._soundPanner.panningModel = this._panningModel;\n      }\n    } else {\n      this._createSpatialParameters();\n    }\n  }\n  /**\n   * Switch the panning model to HRTF:\n   * Renders a stereo output of higher quality than equalpower — it uses a convolution with measured impulse responses from human subjects.\n   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound\n   */\n  switchPanningModelToHRTF() {\n    this._panningModel = \"HRTF\";\n    this._switchPanningModel();\n  }\n  /**\n   * Switch the panning model to Equal Power:\n   * Represents the equal-power panning algorithm, generally regarded as simple and efficient. equalpower is the default value.\n   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-a-spatial-3d-sound\n   */\n  switchPanningModelToEqualPower() {\n    this._panningModel = \"equalpower\";\n    this._switchPanningModel();\n  }\n  _switchPanningModel() {\n    if (Engine.audioEngine?.canUseWebAudio && this._spatialSound && this._soundPanner) {\n      this._soundPanner.panningModel = this._panningModel;\n    }\n  }\n  /**\n   * Connect this sound to a sound track audio node like gain...\n   * @param soundTrackAudioNode the sound track audio node to connect to\n   */\n  connectToSoundTrackAudioNode(soundTrackAudioNode) {\n    if (Engine.audioEngine?.canUseWebAudio && this._outputAudioNode) {\n      if (this._isOutputConnected) {\n        this._outputAudioNode.disconnect();\n      }\n      this._outputAudioNode.connect(soundTrackAudioNode);\n      this._isOutputConnected = true;\n    }\n  }\n  /**\n   * Transform this sound into a directional source\n   * @param coneInnerAngle Size of the inner cone in degree\n   * @param coneOuterAngle Size of the outer cone in degree\n   * @param coneOuterGain Volume of the sound outside the outer cone (between 0.0 and 1.0)\n   */\n  setDirectionalCone(coneInnerAngle, coneOuterAngle, coneOuterGain) {\n    if (coneOuterAngle < coneInnerAngle) {\n      Logger.Error(\"setDirectionalCone(): outer angle of the cone must be superior or equal to the inner angle.\");\n      return;\n    }\n    this._coneInnerAngle = coneInnerAngle;\n    this._coneOuterAngle = coneOuterAngle;\n    this._coneOuterGain = coneOuterGain;\n    this._isDirectional = true;\n    if (this.isPlaying && this.loop) {\n      this.stop();\n      this.play(0, this._offset, this._length);\n    }\n  }\n  /**\n   * Gets or sets the inner angle for the directional cone.\n   */\n  get directionalConeInnerAngle() {\n    return this._coneInnerAngle;\n  }\n  /**\n   * Gets or sets the inner angle for the directional cone.\n   */\n  set directionalConeInnerAngle(value) {\n    if (value != this._coneInnerAngle) {\n      if (this._coneOuterAngle < value) {\n        Logger.Error(\"directionalConeInnerAngle: outer angle of the cone must be superior or equal to the inner angle.\");\n        return;\n      }\n      this._coneInnerAngle = value;\n      if (Engine.audioEngine?.canUseWebAudio && this._spatialSound && this._soundPanner) {\n        this._soundPanner.coneInnerAngle = this._coneInnerAngle;\n      }\n    }\n  }\n  /**\n   * Gets or sets the outer angle for the directional cone.\n   */\n  get directionalConeOuterAngle() {\n    return this._coneOuterAngle;\n  }\n  /**\n   * Gets or sets the outer angle for the directional cone.\n   */\n  set directionalConeOuterAngle(value) {\n    if (value != this._coneOuterAngle) {\n      if (value < this._coneInnerAngle) {\n        Logger.Error(\"directionalConeOuterAngle: outer angle of the cone must be superior or equal to the inner angle.\");\n        return;\n      }\n      this._coneOuterAngle = value;\n      if (Engine.audioEngine?.canUseWebAudio && this._spatialSound && this._soundPanner) {\n        this._soundPanner.coneOuterAngle = this._coneOuterAngle;\n      }\n    }\n  }\n  /**\n   * Sets the position of the emitter if spatial sound is enabled\n   * @param newPosition Defines the new position\n   */\n  setPosition(newPosition) {\n    if (newPosition.equals(this._position)) {\n      return;\n    }\n    this._position.copyFrom(newPosition);\n    if (Engine.audioEngine?.canUseWebAudio && this._spatialSound && this._soundPanner && !isNaN(this._position.x) && !isNaN(this._position.y) && !isNaN(this._position.z)) {\n      this._soundPanner.positionX.value = this._position.x;\n      this._soundPanner.positionY.value = this._position.y;\n      this._soundPanner.positionZ.value = this._position.z;\n    }\n  }\n  /**\n   * Sets the local direction of the emitter if spatial sound is enabled\n   * @param newLocalDirection Defines the new local direction\n   */\n  setLocalDirectionToMesh(newLocalDirection) {\n    this._localDirection = newLocalDirection;\n    if (Engine.audioEngine?.canUseWebAudio && this._connectedTransformNode && this.isPlaying) {\n      this._updateDirection();\n    }\n  }\n  _updateDirection() {\n    if (!this._connectedTransformNode || !this._soundPanner) {\n      return;\n    }\n    const mat = this._connectedTransformNode.getWorldMatrix();\n    const direction = Vector3.TransformNormal(this._localDirection, mat);\n    direction.normalize();\n    this._soundPanner.orientationX.value = direction.x;\n    this._soundPanner.orientationY.value = direction.y;\n    this._soundPanner.orientationZ.value = direction.z;\n  }\n  /** @internal */\n  updateDistanceFromListener() {\n    if (Engine.audioEngine?.canUseWebAudio && this._connectedTransformNode && this.useCustomAttenuation && this._soundGain && this._scene.activeCamera) {\n      const distance = this._scene.audioListenerPositionProvider ? this._connectedTransformNode.position.subtract(this._scene.audioListenerPositionProvider()).length() : this._connectedTransformNode.getDistanceToCamera(this._scene.activeCamera);\n      this._soundGain.gain.value = this._customAttenuationFunction(this._volume, distance, this.maxDistance, this.refDistance, this.rolloffFactor);\n    }\n  }\n  /**\n   * Sets a new custom attenuation function for the sound.\n   * @param callback Defines the function used for the attenuation\n   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#creating-your-own-custom-attenuation-function\n   */\n  setAttenuationFunction(callback) {\n    this._customAttenuationFunction = callback;\n  }\n  /**\n   * Play the sound\n   * @param time (optional) Start the sound after X seconds. Start immediately (0) by default.\n   * @param offset (optional) Start the sound at a specific time in seconds\n   * @param length (optional) Sound duration (in seconds)\n   */\n  play(time, offset, length) {\n    if (this._isReadyToPlay && this._scene.audioEnabled && Engine.audioEngine?.audioContext) {\n      try {\n        this._clearTimeoutsAndObservers();\n        let startTime = time ? Engine.audioEngine?.audioContext.currentTime + time : Engine.audioEngine?.audioContext.currentTime;\n        if (!this._soundSource || !this._streamingSource) {\n          if (this._spatialSound && this._soundPanner) {\n            if (!isNaN(this._position.x) && !isNaN(this._position.y) && !isNaN(this._position.z)) {\n              this._soundPanner.positionX.value = this._position.x;\n              this._soundPanner.positionY.value = this._position.y;\n              this._soundPanner.positionZ.value = this._position.z;\n            }\n            if (this._isDirectional) {\n              this._soundPanner.coneInnerAngle = this._coneInnerAngle;\n              this._soundPanner.coneOuterAngle = this._coneOuterAngle;\n              this._soundPanner.coneOuterGain = this._coneOuterGain;\n              if (this._connectedTransformNode) {\n                this._updateDirection();\n              } else {\n                this._soundPanner.setOrientation(this._localDirection.x, this._localDirection.y, this._localDirection.z);\n              }\n            }\n          }\n        }\n        if (this._streaming) {\n          if (!this._streamingSource) {\n            this._streamingSource = Engine.audioEngine.audioContext.createMediaElementSource(this._htmlAudioElement);\n            this._htmlAudioElement.onended = () => {\n              this._onended();\n            };\n            this._htmlAudioElement.playbackRate = this._playbackRate;\n          }\n          this._streamingSource.disconnect();\n          if (this._inputAudioNode) {\n            this._streamingSource.connect(this._inputAudioNode);\n          }\n          if (this._htmlAudioElement) {\n            // required to manage properly the new suspended default state of Chrome\n            // When the option 'streaming: true' is used, we need first to wait for\n            // the audio engine to be unlocked by a user gesture before trying to play\n            // an HTML Audio element\n            const tryToPlay = () => {\n              if (Engine.audioEngine?.unlocked) {\n                const playPromise = this._htmlAudioElement.play();\n                // In browsers that don’t yet support this functionality,\n                // playPromise won’t be defined.\n                if (playPromise !== undefined) {\n                  playPromise.catch(() => {\n                    // Automatic playback failed.\n                    // Waiting for the audio engine to be unlocked by user click on unmute\n                    Engine.audioEngine?.lock();\n                    if (this.loop || this.autoplay) {\n                      this._audioUnlockedObserver = Engine.audioEngine?.onAudioUnlockedObservable.addOnce(() => {\n                        tryToPlay();\n                      });\n                    }\n                  });\n                }\n              } else {\n                if (this.loop || this.autoplay) {\n                  this._audioUnlockedObserver = Engine.audioEngine?.onAudioUnlockedObservable.addOnce(() => {\n                    tryToPlay();\n                  });\n                }\n              }\n            };\n            tryToPlay();\n          }\n        } else {\n          const tryToPlay = () => {\n            if (Engine.audioEngine?.audioContext) {\n              length = length || this._length;\n              if (offset !== undefined) {\n                this._setOffset(offset);\n              }\n              if (this._soundSource) {\n                const oldSource = this._soundSource;\n                oldSource.onended = () => {\n                  oldSource.disconnect();\n                };\n              }\n              this._soundSource = Engine.audioEngine?.audioContext.createBufferSource();\n              if (this._soundSource && this._inputAudioNode) {\n                this._soundSource.buffer = this._audioBuffer;\n                this._soundSource.connect(this._inputAudioNode);\n                this._soundSource.loop = this.loop;\n                if (offset !== undefined) {\n                  this._soundSource.loopStart = offset;\n                }\n                if (length !== undefined) {\n                  this._soundSource.loopEnd = (offset | 0) + length;\n                }\n                this._soundSource.playbackRate.value = this._playbackRate;\n                this._soundSource.onended = () => {\n                  this._onended();\n                };\n                startTime = time ? Engine.audioEngine?.audioContext.currentTime + time : Engine.audioEngine.audioContext.currentTime;\n                const actualOffset = ((this.isPaused ? this.currentTime : 0) + (this._offset ?? 0)) % this._soundSource.buffer.duration;\n                this._soundSource.start(startTime, actualOffset, this.loop ? undefined : length);\n              }\n            }\n          };\n          if (Engine.audioEngine?.audioContext.state === \"suspended\") {\n            // Wait a bit for FF as context seems late to be ready.\n            this._tryToPlayTimeout = setTimeout(() => {\n              if (Engine.audioEngine?.audioContext.state === \"suspended\") {\n                // Automatic playback failed.\n                // Waiting for the audio engine to be unlocked by user click on unmute\n                Engine.audioEngine.lock();\n                if (this.loop || this.autoplay) {\n                  this._audioUnlockedObserver = Engine.audioEngine.onAudioUnlockedObservable.addOnce(() => {\n                    tryToPlay();\n                  });\n                }\n              } else {\n                tryToPlay();\n              }\n            }, 500);\n          } else {\n            tryToPlay();\n          }\n        }\n        this._startTime = startTime;\n        this.isPlaying = true;\n        this.isPaused = false;\n      } catch (ex) {\n        Logger.Error(\"Error while trying to play audio: \" + this.name + \", \" + ex.message);\n      }\n    }\n  }\n  _onended() {\n    this.isPlaying = false;\n    this._startTime = 0;\n    this._currentTime = 0;\n    if (this.onended) {\n      this.onended();\n    }\n    this.onEndedObservable.notifyObservers(this);\n  }\n  /**\n   * Stop the sound\n   * @param time (optional) Stop the sound after X seconds. Stop immediately (0) by default.\n   */\n  stop(time) {\n    if (this.isPlaying) {\n      this._clearTimeoutsAndObservers();\n      if (this._streaming) {\n        if (this._htmlAudioElement) {\n          this._htmlAudioElement.pause();\n          // Test needed for Firefox or it will generate an Invalid State Error\n          if (this._htmlAudioElement.currentTime > 0) {\n            this._htmlAudioElement.currentTime = 0;\n          }\n        } else {\n          this._streamingSource.disconnect();\n        }\n        this.isPlaying = false;\n      } else if (Engine.audioEngine?.audioContext && this._soundSource) {\n        const stopTime = time ? Engine.audioEngine.audioContext.currentTime + time : undefined;\n        this._soundSource.onended = () => {\n          this.isPlaying = false;\n          this.isPaused = false;\n          this._startTime = 0;\n          this._currentTime = 0;\n          if (this._soundSource) {\n            this._soundSource.onended = () => void 0;\n          }\n          this._onended();\n        };\n        this._soundSource.stop(stopTime);\n      } else {\n        this.isPlaying = false;\n      }\n    } else if (this.isPaused) {\n      this.isPaused = false;\n      this._startTime = 0;\n      this._currentTime = 0;\n    }\n  }\n  /**\n   * Put the sound in pause\n   */\n  pause() {\n    if (this.isPlaying) {\n      this._clearTimeoutsAndObservers();\n      if (this._streaming) {\n        if (this._htmlAudioElement) {\n          this._htmlAudioElement.pause();\n        } else {\n          this._streamingSource.disconnect();\n        }\n        this.isPlaying = false;\n        this.isPaused = true;\n      } else if (Engine.audioEngine?.audioContext && this._soundSource) {\n        this._soundSource.onended = () => void 0;\n        this._soundSource.stop();\n        this.isPlaying = false;\n        this.isPaused = true;\n        this._currentTime += Engine.audioEngine.audioContext.currentTime - this._startTime;\n      }\n    }\n  }\n  /**\n   * Sets a dedicated volume for this sounds\n   * @param newVolume Define the new volume of the sound\n   * @param time Define time for gradual change to new volume\n   */\n  setVolume(newVolume, time) {\n    if (Engine.audioEngine?.canUseWebAudio && this._soundGain) {\n      if (time && Engine.audioEngine.audioContext) {\n        this._soundGain.gain.cancelScheduledValues(Engine.audioEngine.audioContext.currentTime);\n        this._soundGain.gain.setValueAtTime(this._soundGain.gain.value, Engine.audioEngine.audioContext.currentTime);\n        this._soundGain.gain.linearRampToValueAtTime(newVolume, Engine.audioEngine.audioContext.currentTime + time);\n      } else {\n        this._soundGain.gain.value = newVolume;\n      }\n    }\n    this._volume = newVolume;\n  }\n  /**\n   * Set the sound play back rate\n   * @param newPlaybackRate Define the playback rate the sound should be played at\n   */\n  setPlaybackRate(newPlaybackRate) {\n    this._playbackRate = newPlaybackRate;\n    if (this.isPlaying) {\n      if (this._streaming && this._htmlAudioElement) {\n        this._htmlAudioElement.playbackRate = this._playbackRate;\n      } else if (this._soundSource) {\n        this._soundSource.playbackRate.value = this._playbackRate;\n      }\n    }\n  }\n  /**\n   * Gets the sound play back rate.\n   * @returns the  play back rate of the sound\n   */\n  getPlaybackRate() {\n    return this._playbackRate;\n  }\n  /**\n   * Gets the volume of the sound.\n   * @returns the volume of the sound\n   */\n  getVolume() {\n    return this._volume;\n  }\n  /**\n   * Attach the sound to a dedicated mesh\n   * @param transformNode The transform node to connect the sound with\n   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#attaching-a-sound-to-a-mesh\n   */\n  attachToMesh(transformNode) {\n    if (this._connectedTransformNode && this._registerFunc) {\n      this._connectedTransformNode.unregisterAfterWorldMatrixUpdate(this._registerFunc);\n      this._registerFunc = null;\n    }\n    this._connectedTransformNode = transformNode;\n    if (!this._spatialSound) {\n      this._spatialSound = true;\n      this._createSpatialParameters();\n      if (this.isPlaying && this.loop) {\n        this.stop();\n        this.play(0, this._offset, this._length);\n      }\n    }\n    this._onRegisterAfterWorldMatrixUpdate(this._connectedTransformNode);\n    this._registerFunc = transformNode => this._onRegisterAfterWorldMatrixUpdate(transformNode);\n    this._connectedTransformNode.registerAfterWorldMatrixUpdate(this._registerFunc);\n  }\n  /**\n   * Detach the sound from the previously attached mesh\n   * @see https://doc.babylonjs.com/features/featuresDeepDive/audio/playingSoundsMusic#attaching-a-sound-to-a-mesh\n   */\n  detachFromMesh() {\n    if (this._connectedTransformNode && this._registerFunc) {\n      this._connectedTransformNode.unregisterAfterWorldMatrixUpdate(this._registerFunc);\n      this._registerFunc = null;\n      this._connectedTransformNode = null;\n    }\n  }\n  _onRegisterAfterWorldMatrixUpdate(node) {\n    if (!node.getBoundingInfo) {\n      this.setPosition(node.absolutePosition);\n    } else {\n      const mesh = node;\n      const boundingInfo = mesh.getBoundingInfo();\n      this.setPosition(boundingInfo.boundingSphere.centerWorld);\n    }\n    if (Engine.audioEngine?.canUseWebAudio && this._isDirectional && this.isPlaying) {\n      this._updateDirection();\n    }\n  }\n  /**\n   * Clone the current sound in the scene.\n   * @returns the new sound clone\n   */\n  clone() {\n    if (!this._streaming) {\n      const setBufferAndRun = () => {\n        if (this._isReadyToPlay) {\n          clonedSound._audioBuffer = this.getAudioBuffer();\n          clonedSound._isReadyToPlay = true;\n          if (clonedSound.autoplay) {\n            clonedSound.play(0, this._offset, this._length);\n          }\n        } else {\n          setTimeout(setBufferAndRun, 300);\n        }\n      };\n      const currentOptions = {\n        autoplay: this.autoplay,\n        loop: this.loop,\n        volume: this._volume,\n        spatialSound: this._spatialSound,\n        maxDistance: this.maxDistance,\n        useCustomAttenuation: this.useCustomAttenuation,\n        rolloffFactor: this.rolloffFactor,\n        refDistance: this.refDistance,\n        distanceModel: this.distanceModel\n      };\n      const clonedSound = new Sound(this.name + \"_cloned\", new ArrayBuffer(0), this._scene, null, currentOptions);\n      if (this.useCustomAttenuation) {\n        clonedSound.setAttenuationFunction(this._customAttenuationFunction);\n      }\n      clonedSound.setPosition(this._position);\n      clonedSound.setPlaybackRate(this._playbackRate);\n      setBufferAndRun();\n      return clonedSound;\n    }\n    // Can't clone a streaming sound\n    else {\n      return null;\n    }\n  }\n  /**\n   * Gets the current underlying audio buffer containing the data\n   * @returns the audio buffer\n   */\n  getAudioBuffer() {\n    return this._audioBuffer;\n  }\n  /**\n   * Gets the WebAudio AudioBufferSourceNode, lets you keep track of and stop instances of this Sound.\n   * @returns the source node\n   */\n  getSoundSource() {\n    return this._soundSource;\n  }\n  /**\n   * Gets the WebAudio GainNode, gives you precise control over the gain of instances of this Sound.\n   * @returns the gain node\n   */\n  getSoundGain() {\n    return this._soundGain;\n  }\n  /**\n   * Serializes the Sound in a JSON representation\n   * @returns the JSON representation of the sound\n   */\n  serialize() {\n    const serializationObject = {\n      name: this.name,\n      url: this._url,\n      autoplay: this.autoplay,\n      loop: this.loop,\n      volume: this._volume,\n      spatialSound: this._spatialSound,\n      maxDistance: this.maxDistance,\n      rolloffFactor: this.rolloffFactor,\n      refDistance: this.refDistance,\n      distanceModel: this.distanceModel,\n      playbackRate: this._playbackRate,\n      panningModel: this._panningModel,\n      soundTrackId: this.soundTrackId,\n      metadata: this.metadata\n    };\n    if (this._spatialSound) {\n      if (this._connectedTransformNode) {\n        serializationObject.connectedMeshId = this._connectedTransformNode.id;\n      }\n      serializationObject.position = this._position.asArray();\n      serializationObject.refDistance = this.refDistance;\n      serializationObject.distanceModel = this.distanceModel;\n      serializationObject.isDirectional = this._isDirectional;\n      serializationObject.localDirectionToMesh = this._localDirection.asArray();\n      serializationObject.coneInnerAngle = this._coneInnerAngle;\n      serializationObject.coneOuterAngle = this._coneOuterAngle;\n      serializationObject.coneOuterGain = this._coneOuterGain;\n    }\n    return serializationObject;\n  }\n  /**\n   * Parse a JSON representation of a sound to instantiate in a given scene\n   * @param parsedSound Define the JSON representation of the sound (usually coming from the serialize method)\n   * @param scene Define the scene the new parsed sound should be created in\n   * @param rootUrl Define the rooturl of the load in case we need to fetch relative dependencies\n   * @param sourceSound Define a sound place holder if do not need to instantiate a new one\n   * @returns the newly parsed sound\n   */\n  static Parse(parsedSound, scene, rootUrl, sourceSound) {\n    const soundName = parsedSound.name;\n    let soundUrl;\n    if (parsedSound.url) {\n      soundUrl = rootUrl + parsedSound.url;\n    } else {\n      soundUrl = rootUrl + soundName;\n    }\n    const options = {\n      autoplay: parsedSound.autoplay,\n      loop: parsedSound.loop,\n      volume: parsedSound.volume,\n      spatialSound: parsedSound.spatialSound,\n      maxDistance: parsedSound.maxDistance,\n      rolloffFactor: parsedSound.rolloffFactor,\n      refDistance: parsedSound.refDistance,\n      distanceModel: parsedSound.distanceModel,\n      playbackRate: parsedSound.playbackRate\n    };\n    let newSound;\n    if (!sourceSound) {\n      newSound = new Sound(soundName, soundUrl, scene, () => {\n        scene.removePendingData(newSound);\n      }, options);\n      scene.addPendingData(newSound);\n    } else {\n      const setBufferAndRun = () => {\n        if (sourceSound._isReadyToPlay) {\n          newSound._audioBuffer = sourceSound.getAudioBuffer();\n          newSound._isReadyToPlay = true;\n          if (newSound.autoplay) {\n            newSound.play(0, newSound._offset, newSound._length);\n          }\n        } else {\n          setTimeout(setBufferAndRun, 300);\n        }\n      };\n      newSound = new Sound(soundName, new ArrayBuffer(0), scene, null, options);\n      setBufferAndRun();\n    }\n    if (parsedSound.position) {\n      const soundPosition = Vector3.FromArray(parsedSound.position);\n      newSound.setPosition(soundPosition);\n    }\n    if (parsedSound.isDirectional) {\n      newSound.setDirectionalCone(parsedSound.coneInnerAngle || 360, parsedSound.coneOuterAngle || 360, parsedSound.coneOuterGain || 0);\n      if (parsedSound.localDirectionToMesh) {\n        const localDirectionToMesh = Vector3.FromArray(parsedSound.localDirectionToMesh);\n        newSound.setLocalDirectionToMesh(localDirectionToMesh);\n      }\n    }\n    if (parsedSound.connectedMeshId) {\n      const connectedMesh = scene.getMeshById(parsedSound.connectedMeshId);\n      if (connectedMesh) {\n        newSound.attachToMesh(connectedMesh);\n      }\n    }\n    if (parsedSound.metadata) {\n      newSound.metadata = parsedSound.metadata;\n    }\n    return newSound;\n  }\n  _setOffset(value) {\n    if (this._offset === value) {\n      return;\n    }\n    if (this.isPaused) {\n      this.stop();\n      this.isPaused = false;\n    }\n    this._offset = value;\n  }\n  _clearTimeoutsAndObservers() {\n    if (this._tryToPlayTimeout) {\n      clearTimeout(this._tryToPlayTimeout);\n      this._tryToPlayTimeout = null;\n    }\n    if (this._audioUnlockedObserver) {\n      Engine.audioEngine?.onAudioUnlockedObservable.remove(this._audioUnlockedObserver);\n      this._audioUnlockedObserver = null;\n    }\n  }\n}\n/**\n * @internal\n */\nSound._SceneComponentInitialization = _ => {\n  throw _WarnImport(\"AudioSceneComponent\");\n};\n//# sourceMappingURL=sound.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}