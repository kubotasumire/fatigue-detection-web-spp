{"ast":null,"code":"import { __decorate } from \"../../../tslib.es6.js\";\nimport { serialize } from \"../../../Misc/decorators.js\";\nimport { SerializationHelper } from \"../../../Misc/decorators.serialization.js\";\nimport { Observable } from \"../../../Misc/observable.js\";\nimport { Logger } from \"../../../Misc/logger.js\";\nimport { Texture } from \"../../../Materials/Textures/texture.js\";\nimport { GlowLayer } from \"../../../Layers/glowLayer.js\";\nimport { SharpenPostProcess } from \"../../../PostProcesses/sharpenPostProcess.js\";\nimport { ImageProcessingPostProcess } from \"../../../PostProcesses/imageProcessingPostProcess.js\";\nimport { ChromaticAberrationPostProcess } from \"../../../PostProcesses/chromaticAberrationPostProcess.js\";\nimport { GrainPostProcess } from \"../../../PostProcesses/grainPostProcess.js\";\nimport { FxaaPostProcess } from \"../../../PostProcesses/fxaaPostProcess.js\";\nimport { PostProcessRenderPipeline } from \"../../../PostProcesses/RenderPipeline/postProcessRenderPipeline.js\";\nimport { PostProcessRenderEffect } from \"../../../PostProcesses/RenderPipeline/postProcessRenderEffect.js\";\nimport { DepthOfFieldEffect, DepthOfFieldEffectBlurLevel } from \"../../../PostProcesses/depthOfFieldEffect.js\";\nimport { BloomEffect } from \"../../../PostProcesses/bloomEffect.js\";\nimport { RegisterClass } from \"../../../Misc/typeStore.js\";\nimport { EngineStore } from \"../../../Engines/engineStore.js\";\nimport { Tools } from \"../../../Misc/tools.js\";\nimport \"../../../PostProcesses/RenderPipeline/postProcessRenderPipelineManagerSceneComponent.js\";\n/**\n * The default rendering pipeline can be added to a scene to apply common post processing effects such as anti-aliasing or depth of field.\n * See https://doc.babylonjs.com/features/featuresDeepDive/postProcesses/defaultRenderingPipeline\n */\nexport class DefaultRenderingPipeline extends PostProcessRenderPipeline {\n  /**\n   * Enable or disable automatic building of the pipeline when effects are enabled and disabled.\n   * If false, you will have to manually call prepare() to update the pipeline.\n   */\n  get automaticBuild() {\n    return this._buildAllowed;\n  }\n  set automaticBuild(value) {\n    this._buildAllowed = value;\n  }\n  /**\n   * Gets active scene\n   */\n  get scene() {\n    return this._scene;\n  }\n  /**\n   * Enable or disable the sharpen process from the pipeline\n   */\n  set sharpenEnabled(enabled) {\n    if (this._sharpenEnabled === enabled) {\n      return;\n    }\n    this._sharpenEnabled = enabled;\n    this._buildPipeline();\n  }\n  get sharpenEnabled() {\n    return this._sharpenEnabled;\n  }\n  /**\n   * Specifies the size of the bloom blur kernel, relative to the final output size\n   */\n  get bloomKernel() {\n    return this._bloomKernel;\n  }\n  set bloomKernel(value) {\n    this._bloomKernel = value;\n    this.bloom.kernel = value / this._hardwareScaleLevel;\n  }\n  /**\n   * The strength of the bloom.\n   */\n  set bloomWeight(value) {\n    if (this._bloomWeight === value) {\n      return;\n    }\n    this.bloom.weight = value;\n    this._bloomWeight = value;\n  }\n  get bloomWeight() {\n    return this._bloomWeight;\n  }\n  /**\n   * The luminance threshold to find bright areas of the image to bloom.\n   */\n  set bloomThreshold(value) {\n    if (this._bloomThreshold === value) {\n      return;\n    }\n    this.bloom.threshold = value;\n    this._bloomThreshold = value;\n  }\n  get bloomThreshold() {\n    return this._bloomThreshold;\n  }\n  /**\n   * The scale of the bloom, lower value will provide better performance.\n   */\n  set bloomScale(value) {\n    if (this._bloomScale === value) {\n      return;\n    }\n    this._bloomScale = value;\n    // recreate bloom and dispose old as this setting is not dynamic\n    this._rebuildBloom();\n    this._buildPipeline();\n  }\n  get bloomScale() {\n    return this._bloomScale;\n  }\n  /**\n   * Enable or disable the bloom from the pipeline\n   */\n  set bloomEnabled(enabled) {\n    if (this._bloomEnabled === enabled) {\n      return;\n    }\n    this._bloomEnabled = enabled;\n    this._buildPipeline();\n  }\n  get bloomEnabled() {\n    return this._bloomEnabled;\n  }\n  _rebuildBloom() {\n    // recreate bloom and dispose old as this setting is not dynamic\n    const oldBloom = this.bloom;\n    this.bloom = new BloomEffect(this._scene, this.bloomScale, this._bloomWeight, this.bloomKernel / this._hardwareScaleLevel, this._defaultPipelineTextureType, false);\n    this.bloom.threshold = oldBloom.threshold;\n    for (let i = 0; i < this._cameras.length; i++) {\n      oldBloom.disposeEffects(this._cameras[i]);\n    }\n  }\n  /**\n   * If the depth of field is enabled.\n   */\n  get depthOfFieldEnabled() {\n    return this._depthOfFieldEnabled;\n  }\n  set depthOfFieldEnabled(enabled) {\n    if (this._depthOfFieldEnabled === enabled) {\n      return;\n    }\n    this._depthOfFieldEnabled = enabled;\n    this._buildPipeline();\n  }\n  /**\n   * Blur level of the depth of field effect. (Higher blur will effect performance)\n   */\n  get depthOfFieldBlurLevel() {\n    return this._depthOfFieldBlurLevel;\n  }\n  set depthOfFieldBlurLevel(value) {\n    if (this._depthOfFieldBlurLevel === value) {\n      return;\n    }\n    this._depthOfFieldBlurLevel = value;\n    // recreate dof and dispose old as this setting is not dynamic\n    const oldDof = this.depthOfField;\n    this.depthOfField = new DepthOfFieldEffect(this._scene, null, this._depthOfFieldBlurLevel, this._defaultPipelineTextureType, false);\n    this.depthOfField.focalLength = oldDof.focalLength;\n    this.depthOfField.focusDistance = oldDof.focusDistance;\n    this.depthOfField.fStop = oldDof.fStop;\n    this.depthOfField.lensSize = oldDof.lensSize;\n    for (let i = 0; i < this._cameras.length; i++) {\n      oldDof.disposeEffects(this._cameras[i]);\n    }\n    this._buildPipeline();\n  }\n  /**\n   * If the anti aliasing is enabled.\n   */\n  set fxaaEnabled(enabled) {\n    if (this._fxaaEnabled === enabled) {\n      return;\n    }\n    this._fxaaEnabled = enabled;\n    this._buildPipeline();\n  }\n  get fxaaEnabled() {\n    return this._fxaaEnabled;\n  }\n  /**\n   * MSAA sample count, setting this to 4 will provide 4x anti aliasing. (default: 1)\n   */\n  set samples(sampleCount) {\n    if (this._samples === sampleCount) {\n      return;\n    }\n    this._samples = sampleCount;\n    this._buildPipeline();\n  }\n  get samples() {\n    return this._samples;\n  }\n  /**\n   * If image processing is enabled.\n   */\n  set imageProcessingEnabled(enabled) {\n    if (this._imageProcessingEnabled === enabled) {\n      return;\n    }\n    this._scene.imageProcessingConfiguration.isEnabled = enabled;\n  }\n  get imageProcessingEnabled() {\n    return this._imageProcessingEnabled;\n  }\n  /**\n   * If glow layer is enabled. (Adds a glow effect to emmissive materials)\n   */\n  set glowLayerEnabled(enabled) {\n    if (enabled && !this._glowLayer) {\n      this._glowLayer = new GlowLayer(\"\", this._scene);\n    } else if (!enabled && this._glowLayer) {\n      this._glowLayer.dispose();\n      this._glowLayer = null;\n    }\n  }\n  get glowLayerEnabled() {\n    return this._glowLayer != null;\n  }\n  /**\n   * Gets the glow layer (or null if not defined)\n   */\n  get glowLayer() {\n    return this._glowLayer;\n  }\n  /**\n   * Enable or disable the chromaticAberration process from the pipeline\n   */\n  set chromaticAberrationEnabled(enabled) {\n    if (this._chromaticAberrationEnabled === enabled) {\n      return;\n    }\n    this._chromaticAberrationEnabled = enabled;\n    this._buildPipeline();\n  }\n  get chromaticAberrationEnabled() {\n    return this._chromaticAberrationEnabled;\n  }\n  /**\n   * Enable or disable the grain process from the pipeline\n   */\n  set grainEnabled(enabled) {\n    if (this._grainEnabled === enabled) {\n      return;\n    }\n    this._grainEnabled = enabled;\n    this._buildPipeline();\n  }\n  get grainEnabled() {\n    return this._grainEnabled;\n  }\n  /**\n   * Instantiates a DefaultRenderingPipeline.\n   * @param name The rendering pipeline name (default: \"\")\n   * @param hdr If high dynamic range textures should be used (default: true)\n   * @param scene The scene linked to this pipeline (default: the last created scene)\n   * @param cameras The array of cameras that the rendering pipeline will be attached to (default: scene.cameras)\n   * @param automaticBuild If false, you will have to manually call prepare() to update the pipeline (default: true)\n   */\n  constructor(name = \"\", hdr = true, scene = EngineStore.LastCreatedScene, cameras, automaticBuild = true) {\n    super(scene.getEngine(), name);\n    this._camerasToBeAttached = [];\n    /**\n     * ID of the sharpen post process,\n     */\n    this.SharpenPostProcessId = \"SharpenPostProcessEffect\";\n    /**\n     * @ignore\n     * ID of the image processing post process;\n     */\n    this.ImageProcessingPostProcessId = \"ImageProcessingPostProcessEffect\";\n    /**\n     * @ignore\n     * ID of the Fast Approximate Anti-Aliasing post process;\n     */\n    this.FxaaPostProcessId = \"FxaaPostProcessEffect\";\n    /**\n     * ID of the chromatic aberration post process,\n     */\n    this.ChromaticAberrationPostProcessId = \"ChromaticAberrationPostProcessEffect\";\n    /**\n     * ID of the grain post process\n     */\n    this.GrainPostProcessId = \"GrainPostProcessEffect\";\n    /**\n     * Glow post process which adds a glow to emissive areas of the image\n     */\n    this._glowLayer = null;\n    /**\n     * Animations which can be used to tweak settings over a period of time\n     */\n    this.animations = [];\n    this._imageProcessingConfigurationObserver = null;\n    // Values\n    this._sharpenEnabled = false;\n    this._bloomEnabled = false;\n    this._depthOfFieldEnabled = false;\n    this._depthOfFieldBlurLevel = DepthOfFieldEffectBlurLevel.Low;\n    this._fxaaEnabled = false;\n    this._imageProcessingEnabled = true;\n    this._bloomScale = 0.5;\n    this._chromaticAberrationEnabled = false;\n    this._grainEnabled = false;\n    this._buildAllowed = true;\n    /**\n     * This is triggered each time the pipeline has been built.\n     */\n    this.onBuildObservable = new Observable();\n    this._resizeObserver = null;\n    this._hardwareScaleLevel = 1.0;\n    this._bloomKernel = 64;\n    /**\n     * Specifies the weight of the bloom in the final rendering\n     */\n    this._bloomWeight = 0.15;\n    /**\n     * Specifies the luma threshold for the area that will be blurred by the bloom\n     */\n    this._bloomThreshold = 0.9;\n    this._samples = 1;\n    this._hasCleared = false;\n    this._prevPostProcess = null;\n    this._prevPrevPostProcess = null;\n    this._depthOfFieldSceneObserver = null;\n    this._activeCameraChangedObserver = null;\n    this._activeCamerasChangedObserver = null;\n    this._cameras = cameras || scene.cameras;\n    this._cameras = this._cameras.slice();\n    this._camerasToBeAttached = this._cameras.slice();\n    this._buildAllowed = automaticBuild;\n    // Initialize\n    this._scene = scene;\n    const caps = this._scene.getEngine().getCaps();\n    this._hdr = hdr && (caps.textureHalfFloatRender || caps.textureFloatRender);\n    // Misc\n    if (this._hdr) {\n      if (caps.textureHalfFloatRender) {\n        this._defaultPipelineTextureType = 2;\n      } else if (caps.textureFloatRender) {\n        this._defaultPipelineTextureType = 1;\n      }\n    } else {\n      this._defaultPipelineTextureType = 0;\n    }\n    // Attach\n    scene.postProcessRenderPipelineManager.addPipeline(this);\n    const engine = this._scene.getEngine();\n    // Create post processes before hand so they can be modified before enabled.\n    // Block compilation flag is set to true to avoid compilation prior to use, these will be updated on first use in build pipeline.\n    this.sharpen = new SharpenPostProcess(\"sharpen\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, this._defaultPipelineTextureType, true);\n    this._sharpenEffect = new PostProcessRenderEffect(engine, this.SharpenPostProcessId, () => {\n      return this.sharpen;\n    }, true);\n    this.depthOfField = new DepthOfFieldEffect(this._scene, null, this._depthOfFieldBlurLevel, this._defaultPipelineTextureType, true);\n    // To keep the bloom sizes consistent across different display densities, factor in the hardware scaling level.\n    this._hardwareScaleLevel = engine.getHardwareScalingLevel();\n    this._resizeObserver = engine.onResizeObservable.add(() => {\n      this._hardwareScaleLevel = engine.getHardwareScalingLevel();\n      this.bloomKernel = this._bloomKernel;\n    });\n    this.bloom = new BloomEffect(this._scene, this._bloomScale, this._bloomWeight, this.bloomKernel / this._hardwareScaleLevel, this._defaultPipelineTextureType, true);\n    this.chromaticAberration = new ChromaticAberrationPostProcess(\"ChromaticAberration\", engine.getRenderWidth(), engine.getRenderHeight(), 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, this._defaultPipelineTextureType, true);\n    this._chromaticAberrationEffect = new PostProcessRenderEffect(engine, this.ChromaticAberrationPostProcessId, () => {\n      return this.chromaticAberration;\n    }, true);\n    this.grain = new GrainPostProcess(\"Grain\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, this._defaultPipelineTextureType, true);\n    this._grainEffect = new PostProcessRenderEffect(engine, this.GrainPostProcessId, () => {\n      return this.grain;\n    }, true);\n    let avoidReentrancyAtConstructionTime = true;\n    this._imageProcessingConfigurationObserver = this._scene.imageProcessingConfiguration.onUpdateParameters.add(() => {\n      this.bloom._downscale._exposure = this._scene.imageProcessingConfiguration.exposure;\n      if (this.imageProcessingEnabled !== this._scene.imageProcessingConfiguration.isEnabled) {\n        this._imageProcessingEnabled = this._scene.imageProcessingConfiguration.isEnabled;\n        // Avoid re-entrant problems by deferring the call to _buildPipeline because the call to _buildPipeline\n        // at the end of the constructor could end up triggering imageProcessingConfiguration.onUpdateParameters!\n        // Note that the pipeline could have been disposed before the deferred call was executed, but in that case\n        // _buildAllowed will have been set to false, preventing _buildPipeline from being executed.\n        if (avoidReentrancyAtConstructionTime) {\n          Tools.SetImmediate(() => {\n            this._buildPipeline();\n          });\n        } else {\n          this._buildPipeline();\n        }\n      }\n    });\n    this._buildPipeline();\n    avoidReentrancyAtConstructionTime = false;\n  }\n  /**\n   * Get the class name\n   * @returns \"DefaultRenderingPipeline\"\n   */\n  getClassName() {\n    return \"DefaultRenderingPipeline\";\n  }\n  /**\n   * Force the compilation of the entire pipeline.\n   */\n  prepare() {\n    const previousState = this._buildAllowed;\n    this._buildAllowed = true;\n    this._buildPipeline();\n    this._buildAllowed = previousState;\n  }\n  _setAutoClearAndTextureSharing(postProcess, skipTextureSharing = false) {\n    if (this._hasCleared) {\n      postProcess.autoClear = false;\n    } else {\n      postProcess.autoClear = true;\n      this._scene.autoClear = false;\n      this._hasCleared = true;\n    }\n    if (!skipTextureSharing) {\n      if (this._prevPrevPostProcess) {\n        postProcess.shareOutputWith(this._prevPrevPostProcess);\n      } else {\n        postProcess.useOwnOutput();\n      }\n      if (this._prevPostProcess) {\n        this._prevPrevPostProcess = this._prevPostProcess;\n      }\n      this._prevPostProcess = postProcess;\n    }\n  }\n  _buildPipeline() {\n    if (!this._buildAllowed) {\n      return;\n    }\n    this._scene.autoClear = true;\n    const engine = this._scene.getEngine();\n    this._disposePostProcesses();\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);\n      // get back cameras to be used to reattach pipeline\n      this._cameras = this._camerasToBeAttached.slice();\n    }\n    this._reset();\n    this._prevPostProcess = null;\n    this._prevPrevPostProcess = null;\n    this._hasCleared = false;\n    if (this.depthOfFieldEnabled) {\n      // Multi camera suport\n      if (this._cameras.length > 1) {\n        for (const camera of this._cameras) {\n          const depthRenderer = this._scene.enableDepthRenderer(camera);\n          depthRenderer.useOnlyInActiveCamera = true;\n        }\n        this._depthOfFieldSceneObserver = this._scene.onAfterRenderTargetsRenderObservable.add(scene => {\n          if (this._cameras.indexOf(scene.activeCamera) > -1) {\n            this.depthOfField.depthTexture = scene.enableDepthRenderer(scene.activeCamera).getDepthMap();\n          }\n        });\n      } else {\n        this._scene.onAfterRenderTargetsRenderObservable.remove(this._depthOfFieldSceneObserver);\n        const depthRenderer = this._scene.enableDepthRenderer(this._cameras[0]);\n        this.depthOfField.depthTexture = depthRenderer.getDepthMap();\n      }\n      if (!this.depthOfField._isReady()) {\n        this.depthOfField._updateEffects();\n      }\n      this.addEffect(this.depthOfField);\n      this._setAutoClearAndTextureSharing(this.depthOfField._effects[0], true);\n    } else {\n      this._scene.onAfterRenderTargetsRenderObservable.remove(this._depthOfFieldSceneObserver);\n    }\n    if (this.bloomEnabled) {\n      if (!this.bloom._isReady()) {\n        this.bloom._updateEffects();\n      }\n      this.addEffect(this.bloom);\n      this._setAutoClearAndTextureSharing(this.bloom._effects[0], true);\n    }\n    if (this._imageProcessingEnabled) {\n      this.imageProcessing = new ImageProcessingPostProcess(\"imageProcessing\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, this._defaultPipelineTextureType, this.scene.imageProcessingConfiguration);\n      if (this._hdr) {\n        this.addEffect(new PostProcessRenderEffect(engine, this.ImageProcessingPostProcessId, () => {\n          return this.imageProcessing;\n        }, true));\n        this._setAutoClearAndTextureSharing(this.imageProcessing);\n      } else {\n        this._scene.imageProcessingConfiguration.applyByPostProcess = false;\n      }\n      if (!this._cameras || this._cameras.length === 0) {\n        this._scene.imageProcessingConfiguration.applyByPostProcess = false;\n      }\n      if (!this.imageProcessing.getEffect()) {\n        this.imageProcessing._updateParameters();\n      }\n    }\n    if (this.sharpenEnabled) {\n      if (!this.sharpen.isReady()) {\n        this.sharpen.updateEffect();\n      }\n      this.addEffect(this._sharpenEffect);\n      this._setAutoClearAndTextureSharing(this.sharpen);\n    }\n    if (this.grainEnabled) {\n      if (!this.grain.isReady()) {\n        this.grain.updateEffect();\n      }\n      this.addEffect(this._grainEffect);\n      this._setAutoClearAndTextureSharing(this.grain);\n    }\n    if (this.chromaticAberrationEnabled) {\n      if (!this.chromaticAberration.isReady()) {\n        this.chromaticAberration.updateEffect();\n      }\n      this.addEffect(this._chromaticAberrationEffect);\n      this._setAutoClearAndTextureSharing(this.chromaticAberration);\n    }\n    if (this.fxaaEnabled) {\n      this.fxaa = new FxaaPostProcess(\"fxaa\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, this._defaultPipelineTextureType);\n      this.addEffect(new PostProcessRenderEffect(engine, this.FxaaPostProcessId, () => {\n        return this.fxaa;\n      }, true));\n      this._setAutoClearAndTextureSharing(this.fxaa, true);\n    }\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.attachCamerasToRenderPipeline(this._name, this._cameras);\n    }\n    // In multicamera mode, the scene needs to autoclear in between cameras.\n    if (this._scene.activeCameras && this._scene.activeCameras.length > 1 || this._scene.activeCamera && this._cameras.indexOf(this._scene.activeCamera) === -1) {\n      this._scene.autoClear = true;\n    }\n    // The active camera on the scene can be changed anytime\n    if (!this._activeCameraChangedObserver) {\n      this._activeCameraChangedObserver = this._scene.onActiveCameraChanged.add(() => {\n        if (this._scene.activeCamera && this._cameras.indexOf(this._scene.activeCamera) === -1) {\n          this._scene.autoClear = true;\n        }\n      });\n    }\n    if (!this._activeCamerasChangedObserver) {\n      this._activeCamerasChangedObserver = this._scene.onActiveCamerasChanged.add(() => {\n        if (this._scene.activeCameras && this._scene.activeCameras.length > 1) {\n          this._scene.autoClear = true;\n        }\n      });\n    }\n    this._adaptPostProcessesToViewPort();\n    if (!this._enableMSAAOnFirstPostProcess(this.samples) && this.samples > 1) {\n      Logger.Warn(\"MSAA failed to enable, MSAA is only supported in browsers that support webGL >= 2.0\");\n    }\n    this.onBuildObservable.notifyObservers(this);\n  }\n  _disposePostProcesses(disposeNonRecreated = false) {\n    for (let i = 0; i < this._cameras.length; i++) {\n      const camera = this._cameras[i];\n      if (this.imageProcessing) {\n        this.imageProcessing.dispose(camera);\n      }\n      if (this.fxaa) {\n        this.fxaa.dispose(camera);\n      }\n      // These are created in the constructor and should not be disposed on every pipeline change\n      if (disposeNonRecreated) {\n        if (this.sharpen) {\n          this.sharpen.dispose(camera);\n        }\n        if (this.depthOfField) {\n          this._scene.onAfterRenderTargetsRenderObservable.remove(this._depthOfFieldSceneObserver);\n          this.depthOfField.disposeEffects(camera);\n        }\n        if (this.bloom) {\n          this.bloom.disposeEffects(camera);\n        }\n        if (this.chromaticAberration) {\n          this.chromaticAberration.dispose(camera);\n        }\n        if (this.grain) {\n          this.grain.dispose(camera);\n        }\n        if (this._glowLayer) {\n          this._glowLayer.dispose();\n        }\n      }\n    }\n    this.imageProcessing = null;\n    this.fxaa = null;\n    if (disposeNonRecreated) {\n      this.sharpen = null;\n      this._sharpenEffect = null;\n      this.depthOfField = null;\n      this.bloom = null;\n      this.chromaticAberration = null;\n      this._chromaticAberrationEffect = null;\n      this.grain = null;\n      this._grainEffect = null;\n      this._glowLayer = null;\n    }\n  }\n  /**\n   * Adds a camera to the pipeline\n   * @param camera the camera to be added\n   */\n  addCamera(camera) {\n    this._camerasToBeAttached.push(camera);\n    this._buildPipeline();\n  }\n  /**\n   * Removes a camera from the pipeline\n   * @param camera the camera to remove\n   */\n  removeCamera(camera) {\n    const index = this._camerasToBeAttached.indexOf(camera);\n    this._camerasToBeAttached.splice(index, 1);\n    this._buildPipeline();\n  }\n  /**\n   * Dispose of the pipeline and stop all post processes\n   */\n  dispose() {\n    this._buildAllowed = false;\n    this.onBuildObservable.clear();\n    this._disposePostProcesses(true);\n    this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);\n    this._scene._postProcessRenderPipelineManager.removePipeline(this.name);\n    this._scene.autoClear = true;\n    if (this._resizeObserver) {\n      this._scene.getEngine().onResizeObservable.remove(this._resizeObserver);\n      this._resizeObserver = null;\n    }\n    this._scene.onActiveCameraChanged.remove(this._activeCameraChangedObserver);\n    this._scene.onActiveCamerasChanged.remove(this._activeCamerasChangedObserver);\n    this._scene.imageProcessingConfiguration.onUpdateParameters.remove(this._imageProcessingConfigurationObserver);\n    super.dispose();\n  }\n  /**\n   * Serialize the rendering pipeline (Used when exporting)\n   * @returns the serialized object\n   */\n  serialize() {\n    const serializationObject = SerializationHelper.Serialize(this);\n    serializationObject.customType = \"DefaultRenderingPipeline\";\n    return serializationObject;\n  }\n  /**\n   * Parse the serialized pipeline\n   * @param source Source pipeline.\n   * @param scene The scene to load the pipeline to.\n   * @param rootUrl The URL of the serialized pipeline.\n   * @returns An instantiated pipeline from the serialized object.\n   */\n  static Parse(source, scene, rootUrl) {\n    return SerializationHelper.Parse(() => new DefaultRenderingPipeline(source._name, source._name._hdr, scene), source, scene, rootUrl);\n  }\n}\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"sharpenEnabled\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomKernel\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"_bloomWeight\", void 0);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"_bloomThreshold\", void 0);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"_hdr\", void 0);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomWeight\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomThreshold\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomScale\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomEnabled\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"depthOfFieldEnabled\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"depthOfFieldBlurLevel\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"fxaaEnabled\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"samples\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"imageProcessingEnabled\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"glowLayerEnabled\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"chromaticAberrationEnabled\", null);\n__decorate([serialize()], DefaultRenderingPipeline.prototype, \"grainEnabled\", null);\nRegisterClass(\"BABYLON.DefaultRenderingPipeline\", DefaultRenderingPipeline);\n//# sourceMappingURL=defaultRenderingPipeline.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}